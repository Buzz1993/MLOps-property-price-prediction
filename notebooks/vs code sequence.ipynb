{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d1b174-13be-4082-b87d-ece2914ce071",
   "metadata": {},
   "source": [
    "# once your project will complete then only detele this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc07c57-807a-4a61-817b-a6e599a2a40a",
   "metadata": {},
   "source": [
    "correct vs code 1  \n",
    "where we do data cleaning\n",
    "in this below code i have make separate dataframe for df and am_df\n",
    "and in this below code removing of 4 columns which I have created in \"4.property_missingness_identification\" is not added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269e6246-ad2d-4d65-9368-a2d13474acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "import ast\n",
    "\n",
    "def basic_cleaning(data : pd.DataFrame):\n",
    "    df = data.copy()\n",
    "    \n",
    "    #convert column names into lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    #drop unwanted columns\n",
    "    df.drop(['@id','@type','bhk_type' ,'locality_url','md_booking amount','md_loan offered','md_water availability','ap_price','ap_price per sqft','ap_configuration',\n",
    "              'ap_pjt_url','ap_ratings','ap_reviews_by','headings_with_ratings','aboutpjt_bhk','2 bhk flat','locality_url_review','liv_environment','liv_commuting',\n",
    "              'liv_places of interest','md_status of electricity','3 bhk flat','1 bhk flat','studio apartment','4 bhk flat','5 bhk flat','md_landmarks', \n",
    "              'multistorey apartment', '3 bhk villa', '4 bhk villa', 'residential plot', '2 bhk builder', '3 bhk builder','4 bhk penthouse','5 bhk penthouse', \n",
    "              'md_authority approval','6 bhk flat','rent','commercial office space','3 bhk penthouse','md_rera id','aboutpjt_launch date'],axis=1,inplace=True)\n",
    "    \n",
    "    #drop duplicate rows\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    #delete column which have all nan values\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "    df[df.select_dtypes('object').columns] = df.select_dtypes('object').apply(\n",
    "        lambda col: col.map(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "    )\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #function 1\n",
    "    def check_more_than_one_value_in_column(df, cols, new_col_name, col_name):\n",
    "        # Step 1: Create a boolean column to check if more than one value (non-NaN) is filled in the specified columns\n",
    "        df[new_col_name] = df[cols].notna().sum(axis=1) > 1\n",
    "    \n",
    "        # Step 2: Combine all values from the specified columns into a list for each row\n",
    "        def combine_values():\n",
    "            df[col_name] = [list(values) for values in zip(*[df[col] for col in cols])]\n",
    "    \n",
    "        combine_values()\n",
    "    \n",
    "        found_distinct = False\n",
    "    \n",
    "        # Step 3: If any row has more than one value\n",
    "        if df[new_col_name].any():\n",
    "            for index, row in df[col_name].items():\n",
    "                non_nan_vals = [val for val in row if pd.notna(val)]\n",
    "                # Step 4: If more than one unique value found in the row, print that row\n",
    "                if len(set(non_nan_vals)) > 1: #take rows which have more than one unique value \n",
    "                    print(f\"Row {index} has multiple distinct non-NaN values: {row}\") \n",
    "                    found_distinct = True  #if get more than 1 distinct value then below thing wont run\n",
    "    \n",
    "        # Step 5: If no row has more than one unique value, safely pick the first non-NaN value\n",
    "        if not found_distinct:\n",
    "            df[col_name] = df[col_name].apply(lambda row: next((val for val in row if pd.notna(val)), None))\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #function2\n",
    "    def combine_first_valid(df, source_cols, new_col_name):\n",
    "        \"\"\"\n",
    "        Create a new column with the first valid (non-null, non-'nan', non-empty) value \n",
    "        across the specified source columns.\n",
    "        \"\"\"\n",
    "        # Combine columns into new_col_name using first valid value per row\n",
    "        df[new_col_name] = df[source_cols].apply(\n",
    "            lambda row: next(\n",
    "                (str(x) for x in row if pd.notna(x) and str(x).strip().lower() != 'nan' and str(x).strip() != ''),\n",
    "                np.nan\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Normalize the new column's casing and whitespace\n",
    "        df[new_col_name] = df[new_col_name].str.strip().str.lower()\n",
    "    \n",
    "        # Drop the source columns\n",
    "        df.drop(columns=source_cols, inplace=True)\n",
    "    \n",
    "        return df\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #emi\n",
    "    converted_emi = []\n",
    "\n",
    "    for emi_n in df['emi']:\n",
    "        if isinstance(emi_n, str):  # Check if emi_n is a string\n",
    "            if 'k' in emi_n:\n",
    "                # Convert from thousands to lakhs\n",
    "                converted_emi.append(float(emi_n.replace('k', '')) / 100)\n",
    "            elif 'l' in emi_n:\n",
    "                # No change needed for lakhs\n",
    "                converted_emi.append(float(emi_n.replace('l', '')))\n",
    "            else:\n",
    "                # Convert rupees to lakhs\n",
    "                converted_emi.append(float(emi_n) / 100000)\n",
    "        else:\n",
    "            # If it's already a float, convert rupees to lakhs\n",
    "            converted_emi.append(emi_n / 100000)\n",
    "    \n",
    "    # Add the converted values to the DataFrame\n",
    "    df['converted_emi'] = converted_emi\n",
    "    df = df.drop(['emi'], axis=1)\n",
    "    df.rename(columns={'converted_emi': 'emi'}, inplace=True)\n",
    "        \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # numerical column\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #price\n",
    "    def convert_price_to_cr(val):\n",
    "        if isinstance(val, str):  # check if value is a string\n",
    "            parts = val.replace('₹', '').split()  # remove ₹ and split into amount and unit\n",
    "            if len(parts) == 2:  # ensure both amount and unit exist\n",
    "                amount, unit = parts\n",
    "                amount = float(amount)  \n",
    "                return amount / 100 if unit.lower() == 'lac' else amount  # convert lac to Cr\n",
    "        return None  # return None if invalid\n",
    "    \n",
    "    # Apply conversion\n",
    "    df['price'] = df['price'].apply(convert_price_to_cr)\n",
    "\n",
    "    #datatype to float\n",
    "    df['price'] = df['price'].astype('float64')\n",
    "    \n",
    "    # Drop rows with missing prices\n",
    "    df = df.dropna(subset=['price'])\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #bed\n",
    "    check_more_than_one_value_in_column(df, ['numberofrooms', 'bb_beds', 'leftbb_beds', 'bb_bed','leftbb_bed'], 'multi_bed_filled','bed')  \n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #bath\n",
    "    check_more_than_one_value_in_column(df, ['bb_baths', 'leftbb_baths', 'bb_bath', 'leftbb_bath'], 'multi_bath_filled','bath')  \n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #parking\n",
    "    # Convert 'leftmany_car parking' into sum of all digits\n",
    "    df['leftmany_car parking'] = df['leftmany_car parking'].apply(\n",
    "        lambda x: sum(map(int, re.findall(r'\\d+', str(x)))) if pd.notna(x) else np.nan\n",
    "    )\n",
    "    \n",
    "    # Convert 'many_car parking' into sum of all digits\n",
    "    df['many_car parking'] = df['many_car parking'].apply(\n",
    "        lambda x: sum(map(int, re.findall(r'\\d+', str(x)))) if pd.notna(x) else np.nan\n",
    "    )\n",
    "    \n",
    "    # Take max across the four parking columns\n",
    "    df['parking'] = df[\n",
    "        ['bb_covered-parking', 'leftbb_covered-parking', 'many_car parking', 'leftmany_car parking']\n",
    "    ].apply(\n",
    "        lambda row: np.nanmax(row.values) if pd.notna(row).any() else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #area and costpersqft     \n",
    "\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['area_work'] = df[\"many_carpet area\"].combine_first(df[\"leftmany_carpet area\"])\n",
    "\n",
    "\n",
    "    # Extract carpet area features\n",
    "    df[\"carpet_area\"] = df[\"area_work\"].apply(lambda x: float(re.match(r'([\\d,\\.]+)', x).group(1).replace(',', '')) if pd.notna(x) and re.match(r'^[\\d,\\.]+', x) else None) \n",
    "    df['cost_per_sqft'] = df['area_work'].str.extract(r'₹([\\d,\\.]+)')[0].str.replace(',', '').astype(float)\n",
    "    df['area_unit'] = df['area_work'].str.extract(r'/([^/]+)$')\n",
    "    \n",
    "    # Remove unwanted area units\n",
    "    df = df[~df['area_unit'].isin(['sqm', 'kanal'])]\n",
    "    \n",
    "    # Combine super built-up area\n",
    "    df['super_build_area_work'] = df[\"leftmany_super built-up area\"].combine_first(df[\"many_super built-up area\"])\n",
    "    \n",
    "    \n",
    "    # Extract super built-up features\n",
    "    df['initial_unit'] = df['super_build_area_work'].apply(lambda x: ''.join([char for char in str(x)[re.match(r'\\d+', str(x)).end():] if char.isalpha()])[:4] if isinstance(x, str) else None)\n",
    "    df = df[~df['initial_unit'].isin(['sqms', 'sqyr'])]\n",
    "    df[\"super_build_up_area\"] = df[\"super_build_area_work\"].apply(lambda x: float(re.match(r'([\\d,\\.]+)', x).group(1).replace(',', '')) if pd.notna(x) and re.match(r'^[\\d,\\.]+', x) else None)\n",
    "    df['super_build_up_cost_per_sqft'] = df['super_build_area_work'].str.extract(r'₹([\\d,\\.]+)')[0].str.replace(',', '').astype(float)\n",
    "    df['super_built_up_area_unit'] = df['super_build_area_work'].str.extract(r'/([^/]+)$')\n",
    "    \n",
    "    # Final feature selection with combine_first\n",
    "    df['f_area'] = df[\"carpet_area\"].combine_first(df[\"super_build_up_area\"])\n",
    "    df['f_costpersqft'] = df[\"cost_per_sqft\"].combine_first(df[\"super_build_up_cost_per_sqft\"])\n",
    "    df['f_area_unit'] = df[\"super_built_up_area_unit\"].combine_first(df[\"area_unit\"])\n",
    "    df['f_area'] = df['f_area'].astype('float')\n",
    "    df['f_costpersqft'] = df['f_costpersqft'].astype('float')\n",
    "    \n",
    "    \n",
    "    # Fill missing values from 'area' column\n",
    "    df['dupli_f_area'] = np.where(\n",
    "        pd.isna(df['f_area']) & pd.notna(df['area']),\n",
    "        df['area'].str.extract(r'([\\d,\\.]+)')[0].str.replace(',', '').astype(float),\n",
    "        None\n",
    "    )\n",
    "    \n",
    "    df['dupli_f_area_unit'] = np.where(\n",
    "        pd.isna(df['f_area']) & pd.notna(df['area']),\n",
    "        df['area'].str.extract(r'([a-zA-Z\\-]+)$')[0],\n",
    "        None\n",
    "    )\n",
    "    \n",
    "    df['dupli_price'] = df.apply(\n",
    "        lambda row: row['price'] * (10**7) if pd.isna(row['f_area']) and pd.notna(row['area'])\n",
    "        else None,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    df['dupli_costpersqft'] = np.round(df['dupli_price'].astype('float') / df['dupli_f_area'].astype('float'), 2)\n",
    "    \n",
    "    # Update final columns if missing\n",
    "    def update_values(df, update_cols, using_cols):\n",
    "        for update_col, using_col in zip(update_cols, using_cols):\n",
    "            df[update_col] = np.where(\n",
    "                pd.isna(df['f_area']) & pd.notna(df['area']),\n",
    "                df[using_col],\n",
    "                df[update_col]\n",
    "            )\n",
    "        return df\n",
    "    \n",
    "    # Define columns to update and corresponding columns to use\n",
    "    columns_to_update = ['f_costpersqft', 'f_area_unit', 'f_area']\n",
    "    using_columns = ['dupli_costpersqft', 'dupli_f_area_unit', 'dupli_f_area']\n",
    "    \n",
    "    # Update the DataFrame\n",
    "    df = update_values(df, columns_to_update, using_columns)\n",
    "    \n",
    "    # Drop intermediate columns\n",
    "    cols_to_drop = [\n",
    "        'many_carpet area', 'leftmany_carpet area', 'leftmany_super built-up area', 'many_super built-up area', 'area',\n",
    "        'area_work', 'carpet_area', 'cost_per_sqft', 'area_unit', 'initial_unit',\n",
    "        'super_build_area_work', 'super_build_up_area', 'super_build_up_cost_per_sqft', 'super_built_up_area_unit',\n",
    "        'dupli_f_area', 'dupli_f_area_unit', 'dupli_price', 'dupli_costpersqft', 'f_area_unit'\n",
    "    ]\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "    df = df.rename(columns={'f_area':'area','f_costpersqft':'costpersqft'})\n",
    "\n",
    "    df['area'] = df['area'].astype('float64')\n",
    "\n",
    "    #After analyzing, found some errors in the area column; hence, dropped the rows with the below id's\n",
    "    df = df[~df['id'].isin([\n",
    "        'cardid13695470', 'cardid72545677', 'cardid71119645',\n",
    "        'cardid46503375', 'cardid48667071', 'cardid72200975',\n",
    "        'cardid70294971', 'cardid70608749', 'cardid72754063',\n",
    "        'cardid72078141', 'cardid71460761', 'cardid45089373',\n",
    "        'cardid71419541', 'cardid72848693', 'cardid73238137'\n",
    "    ])]\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #total_floor and flat_on_floor\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['floor_work_1'] = df['many_floor'].combine_first(df['leftmany_floor'])\n",
    "\n",
    "    df['floor_work_1'] = df['floor_work_1'].astype('str') \n",
    "\n",
    "    df['flat_on_floor'] = df['floor_work_1'].apply(\n",
    "        lambda x: x.split('(')[0].strip() if '(' in str(x) else None\n",
    "    )\n",
    "\n",
    "    df['total_floor'] = df['floor_work_1'].apply(\n",
    "        lambda x: x.split('(')[1].strip() if '(' in str(x) else None\n",
    "    )\n",
    "\n",
    "    df['total_floor'] = df['total_floor'].str.extract(r'(\\d+)').astype(float)\n",
    "    \n",
    "    df['flat_on_floor'] = df['flat_on_floor'].replace({'lower basement': -1, 'upper basement': -2,'ground':0})\n",
    "\n",
    "    df['total_floor'] = np.where(\n",
    "        pd.isna(df['total_floor']) & pd.notna(df['md_floors allowed for construction']),\n",
    "        df['md_floors allowed for construction'],\n",
    "        df['total_floor']\n",
    "    )\n",
    "\n",
    "    df['flat_on_floor'] = df['flat_on_floor'].astype('float64')\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #lift\n",
    "    check_more_than_one_value_in_column(df, ['many_lifts', 'md_lift', 'leftmany_lifts', 'many_lift','leftmany_lift'], 'multi_lift_filled','lift') \n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #balcony\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['balcony'] = (\n",
    "        df['bb_balcony']\n",
    "        .combine_first(df['leftbb_balcony'])\n",
    "        .combine_first(df['bb_balconies'])\n",
    "        .combine_first(df['leftbb_balconies'])\n",
    "    )\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #longitude and lattitude\n",
    "    df['lattitude'] = df['geo'].str.split(',').str[1].str.split(':').str[1].str.strip(\" '\\\"\").astype('float')\n",
    "    df['longitude'] = df['geo'].str.split(',').str[2].str.split(':').str[1].str.strip(\" '\\\"}\").astype('float')\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #project_in_acres\n",
    "    # Conversion function for different units to acres\n",
    "    def convert_to_acres(value):\n",
    "        if isinstance(value, str):  # Check if the value is a string\n",
    "            if 'acre' in value:\n",
    "                acres = float(value.replace('acre', '').strip())\n",
    "                return round(acres, 4)  \n",
    "            elif 'sq-m' in value:\n",
    "                sqm = float(value.replace('sq-m', '').strip())\n",
    "                return round(sqm * 0.000247105, 4)  \n",
    "            elif 'sq-ft' in value:\n",
    "                sqft = float(value.replace('sq-ft', '').strip())\n",
    "                return round(sqft * 0.0000229568, 4)  \n",
    "            elif 'hectare' in value:\n",
    "                hectares = float(value.replace('hectare', '').strip())\n",
    "                return round(hectares * 2.47105, 4)  \n",
    "            elif 'sq-yrd' in value:\n",
    "                sq_yrd = float(value.replace('sq-yrd', '').strip())\n",
    "                return round(sq_yrd * 0.000836127, 4)  \n",
    "        elif isinstance(value, (int, float)):  # If value is numeric\n",
    "            return round(value * 0.0000229568, 4)  \n",
    "        return np.nan\n",
    "    \n",
    "    # Apply the conversion to the column\n",
    "    df['project_in_acres'] = df['aboutpjt_project size'].apply(lambda x: convert_to_acres(x))\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    #categorical column\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #builder\n",
    "    df = combine_first_valid(\n",
    "        df,\n",
    "        source_cols=['many_developer','leftmany_developer','ap_buildr'],\n",
    "        new_col_name='builder'\n",
    "    )\n",
    "\n",
    "    def standardize_property_name(name):\n",
    "        \"\"\"\n",
    "        Standardize property names to a single consistent name.\n",
    "        \"\"\"\n",
    "        # Define a mapping of possible variations to standardized names\n",
    "        mapping = {\n",
    "            \"a&o realty / a and o realty / a & o realty ltd.\": \"a&o realty\",\n",
    "            \"adhiraj constructions / adhiraj constructions pvt. ltd.\": \"adhiraj constructions\",\n",
    "            \"arihant superstructures ltd / arihant superstructures ltd.\": \"arihant superstructures ltd\",\n",
    "            \"bharat infrastructure & engineering pvt. ltd. / bharat infrastructure and engineering\": \"bharat infrastructure & engineering\",\n",
    "            \"bhoomi group / bhoomi / bhoomi properties\": \"bhoomi group\",\n",
    "            \"choice group of companies / choice group\": \"choice group\",\n",
    "            \"darshan properties / darshan properties group\": \"darshan properties\",\n",
    "            \"dev land housing / dev land housing ltd.\": \"dev land housing\",\n",
    "            \"ecohomes / eco homes\": \"ecohomes\",\n",
    "            \"gundecha developers / gundecha / gundecha developing milestone /gundecha group\": \"gundecha group\",\n",
    "            \"hiranandani communities / hiranandani constructions / hiranandani developers / hiranandani group / house of hiranandani\": \"hiranandani group\",\n",
    "            \"k raheja realty/ k. raheja realty\": \"k raheja realty\",\n",
    "            \"krishna enterprise / krishna enterprises\": \"krishna enterprise\",\n",
    "            \"l & t realty / l&t realty\": \"l&t realty\",\n",
    "            \"lodha / lodha group\": \"lodha group\",\n",
    "            \"lok housing group / lok group\": \"lok housing group\",\n",
    "            \"lokhandwala builders / lokhandwala constructions / lokhandwala construction industries pvt. ltd. / lokhandwala group\": \"lokhandwala group\",\n",
    "            \"lokhandwala infrastructure\": \"lokhandwala infrastructure\",\n",
    "            \"lotus logistic and developers / lotus logistics & developer pvt ltd\": \"lotus logistics\",\n",
    "            \"neelam realtors / neelam realtors pvt. ltd.\": \"neelam realtors\",\n",
    "            \"neelsidhi group / neelsidhi\": \"neelsidhi group\",\n",
    "            \"nirmal lifestyle / nirmal life style\": \"nirmal lifestyle\",\n",
    "            \"omkar realtors and developers pvt. ltd. / omkar realtors\": \"omkar realtors\",\n",
    "            \"parinee developers / parinee group\": \"parinee group\",\n",
    "            \"platinum group / platinum group builders / platinum constructions\": \"platinum group\",\n",
    "            \"prescon group / prescon\": \"prescon group\",\n",
    "            \"puraniks builders / puranik builders ltd. / puranik group\": \"puraniks group\",\n",
    "            \"r k builders / r k builders and developers\": \"r k builders\",\n",
    "            \"qualcon properties llp / qualcon\": \"qualcon\",\n",
    "            \"raheja universal (pvt.) ltd. / raheja universal pvt. ltd.\": \"raheja universal\",\n",
    "            \"raheja developers / raheja developers ltd.\": \"raheja developers\",\n",
    "            \"raj realty group / raj realty\": \"raj realty group\",\n",
    "            \"rashmi housing pvt. ltd. / rashmi housing\": \"rashmi housing\",\n",
    "            \"ravi group of builders and developers / ravi group\": \"ravi group\",\n",
    "            \"rna / rna ng builders / rna corp / rna group\": \"rna group\",\n",
    "            \"rohan lifescapes / rohan lifescapes ltd.\": \"rohan lifescapes\",\n",
    "            \"romell group / romell real estate pvt. ltd.\": \"romell group\",\n",
    "            \"rustomjee / rustomjee developers\": \"rustomjee\",\n",
    "            \"sahajanand developers / sahajanand infrastructure pvt. ltd.\": \"sahajanand developers\",\n",
    "            \"sainath developers / sainath group\": \"sainath developers\",\n",
    "            \"sapphire group and builder / sapphire group\": \"sapphire group\",\n",
    "            \"saptashree builders & developers / sapta shree builders & developers\": \"saptashree\",\n",
    "            \"shapoorji pallonji real estate / shapoorji pallonji group\": \"shapoorji pallonji group\",\n",
    "            \"sheth creators / sheth creators pvt. ltd.\": \"sheth creators\",\n",
    "            \"shree ostwal builders ltd. / shree ostwal builders and developers\": \"shree ostwal builders\",\n",
    "            \"shreedham builders and developers / shreedham group\": \"shreedham group\",\n",
    "            \"shreeji construction / shreeji group / shreeji group builder and developer\": \"shreeji group\",\n",
    "            \"smgk associates / smgk group\": \"smgk group\",\n",
    "            \"space india / space india builders & developers\": \"space india\",\n",
    "            \"spenta builders / spenta corp. pvt. ltd.\": \"spenta\",\n",
    "            \"sugee realty & developers (india) pvt. ltd. / sugee group\": \"sugee group\",\n",
    "            \"swastik realtors / swastik group builders & developers\": \"swastik\",\n",
    "            \"tharwani realty / tharwani group\": \"tharwani group\",\n",
    "            \"titanium group / titanium builders and developers\": \"titanium group\",\n",
    "            \"today global homes / today global builders & developers\": \"today global\",\n",
    "            \"transcon developers / transcon group\": \"transcon group\",\n",
    "            \"tridhaatu realty / tridhaatu realty & infra pvt. ltd.\": \"tridhaatu realty\",\n",
    "            \"vaibhavlaxmi builders & developers / vaibhavlaxmi builders and developers / vaibhav laxmi developers\": \"vaibhavlaxmi builders\",\n",
    "            \"vbhc value homes pvt. ltd. / vbhc\": \"vbhc\",\n",
    "            \"vihang infrastructure pvt ltd / vihang group\": \"vihang group\",\n",
    "            \"vinay unique developers / vinay unique group\": \"vinay unique group\"\n",
    "        }\n",
    "    \n",
    "        # Handle null or missing values\n",
    "        if not isinstance(name, str):\n",
    "            return name\n",
    "    \n",
    "        # Normalize input name (e.g., lowercase, strip whitespace)\n",
    "        normalized_name = name.strip().lower()\n",
    "    \n",
    "        # Standardize using the mapping\n",
    "        for key, value in mapping.items():\n",
    "            variations = key.split(\" / \")\n",
    "            if normalized_name in variations:\n",
    "                return value\n",
    "    \n",
    "        # Return the original name if no match is found\n",
    "        return name\n",
    "    \n",
    "    # Apply the function to the 'builder' column of a DataFrame\n",
    "    df['builder'] = df['builder'].apply(standardize_property_name)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #project_name\n",
    "    df = combine_first_valid(\n",
    "        df,\n",
    "        source_cols=['ap_pjt_name', 'many_project', 'leftmany_project'],\n",
    "        new_col_name='project_name'\n",
    "    )\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #furnish\n",
    "    df = combine_first_valid(\n",
    "        df,\n",
    "        source_cols=['md_furnishing','many_furnished status','leftmany_furnished status'],\n",
    "        new_col_name='furnish'\n",
    "    )\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #city\n",
    "    df = df.rename(columns={'address':'wholeaddress'})\n",
    "\n",
    "    df['addressregion'] = df['wholeaddress'].apply(\n",
    "        lambda x: ast.literal_eval(x).get('addressregion') if isinstance(x, str) else x.get('addressregion')\n",
    "    )\n",
    "\n",
    "    \n",
    "    #rename\n",
    "    df = df.rename(columns={'md_address':'address'})\n",
    "\n",
    "    df = df.rename(columns = {'addressregion':'city'})\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #location\n",
    "    # Convert string representation of dictionaries to actual dictionaries\n",
    "    df[\"wholeaddress\"] = df[\"wholeaddress\"].apply(ast.literal_eval)\n",
    "    \n",
    "    # Extract 'addresslocality' into a new column\n",
    "    df[\"location\"] = df[\"wholeaddress\"].apply(lambda x: x.get(\"addresslocality\", \"\"))\n",
    "    \n",
    "    #make rd as road in address column\n",
    "    df['address'] = df['address'].astype(str).str.replace(r'\\brd\\b', 'road', regex=True)\n",
    "    \n",
    "    #if below values match found in address column,then update location with the matched value\n",
    "    \n",
    "    lst = [\n",
    "        \"mira road east\", \"mira road west\", \"mira rd east\", \"mira rd west\",\n",
    "        \"vile parle east\", \"vile parle west\", \"lower parel west\", \"lower parel east\",\n",
    "        \"new panvel east\", \"new panvel west\", \"grand road east\", \"grand road west\",\n",
    "        \"charni road east\", \"charni road west\", \"grand rd east\", \"grand rd west\",\n",
    "        \"charni rd east\", \"charni rd west\", \"kanjur marg east\", \"kanjur marg west\",\n",
    "        \"mira bhayandar east\", \"mira bhayandar west\", \"marine lines east\", \"marine lines west\",\n",
    "        \"ram mandir west\", \"ram mandir east\", \"vasai road west\", \"vasai road east\",\n",
    "        \"matunga road west\", \"matunga road east\", \"vasai rd west\", \"vasai rd east\",\n",
    "        \"matunga rd west\", \"matunga rd east\", \"rajendra nagar west\", \"rajendra nagar east\",\n",
    "        \"tilak nagar west\", \"tilak nagar east\", \"diva station east\", \"diva station west\",\n",
    "        \"ville parla west\", \"ville parla east\", \"lower pare west\", \"lower pare east\",\n",
    "        \"mumbai central east\", \"mumbai central west\"\n",
    "    ]\n",
    "    # Step 1: Filter NaN rows\n",
    "    df_nan1 = df[df['location'].isna()].copy()\n",
    "    \n",
    "    # Step 2 & 3: Match with lst and update location\n",
    "    for index, row in df_nan1.iterrows():\n",
    "        for loc in lst:\n",
    "            if loc in row['address'].lower():  # Case insensitive match\n",
    "                df.at[index, 'location'] = loc\n",
    "                break  # Stop at first match\n",
    "\n",
    "    # Function to extract \"<name> east\" or \"<name> west\" from 'address'\n",
    "    def extract_location(address):\n",
    "        # Use regex to find a word followed by 'east' or 'west'\n",
    "        match = re.search(r'(\\w+)\\s+(east|west)', address, re.IGNORECASE)\n",
    "        if match:\n",
    "            return f\"{match.group(1)} {match.group(2)}\"\n",
    "        return np.nan  # If no match, return NaN\n",
    "    \n",
    "    # Filter the rows where 'location' is NaN\n",
    "    df_nan2 = df[df['location'].isna()]\n",
    "    \n",
    "    # Apply the extract_location function only to the 'address' column in the filtered rows\n",
    "    df.loc[df_nan2.index, 'location'] = df_nan2['address'].apply(extract_location)\n",
    "    \n",
    "    mapping = {\"near naupada police station, thane, maharashtra\" : \"thane west\",\n",
    "            \"new suyash chs naupada, thane, maharashtra\" : \"thane west\",\n",
    "            \"marine lines, mumbai, maharashtra\" : \"marine lines\",\n",
    "            \"kalher, thane, maharashtra\" : \"bhiwandi\",\n",
    "            \"kanikiya beverly park mira road, mumbai, maharashtra\" : \"mira road east\",\n",
    "            \"204, 2nd flr, ramraj bldg, nr. ram mandir, rajanpada - sector-27, navi mumbai, maharashtra\" : \"sector 27 rajanpada\",\n",
    "            \"202 dhrmasetu plot no 2225 sec 19 koperkhairane, navi mumbai, maharashtra\" : \"sector 19 koperkhairane\",\n",
    "            \"kashimira near whestran express hyway, mumbai, maharashtra\" : \"mira road east\",\n",
    "            \"near burhani college mazgaon mumbai 10, mumbai, maharashtra\" : \"mazgaon\",\n",
    "            \"ulwe sector 21, navi mumbai, maharashtra\" : \"sector 21 ulwe\",\n",
    "            \"lakeshore greens by lodha, thane, maharashtra\" : \"dombivli west\",\n",
    "            \"santa cruz, mumbai, maharashtra\" : \"santacruz\",\n",
    "            \"kopar khairane, navi mumbai, maharashtra\" : \"koparkhairane\",\n",
    "            \"1801, 18th floor, chunam lane, lamington road, grantroad e, mumbai 400007, mumbai, maharashtra\" : \"grant road east\",\n",
    "            \"charkop village near dingeshwar talao and jalaram temple, mumbai, maharashtra\" : \"kandivali west\",\n",
    "            \"sarfaraz iqbal heights, ymca road 3, near maratha mandir, mumbai central, mumbai, maharashtra\" : \"mumbai central\",\n",
    "            \"panchseel heights, mahavir nagar, mumbai, maharashtra\" : \"kandivali west\",\n",
    "            \"sector 5 pushpak nagar, navi mumbai, maharashtra\" : \"sector 5 pushpak nagar\",\n",
    "            \"poonam park view, global city, virar, thane, maharashtra\" : \"virar west\",\n",
    "            \"om ekdant soc, sec-19, koperkharine, near jummy tower, navi mumbai, maharashtra\" : \"sector 19 koperkharine\",\n",
    "            \"sai vrindhavan koparkhairne., navi mumbai, maharashtra\" : \"koparkhairne\",\n",
    "            \"owale, ghodbunder road, thane, maharashtra\" : \"thane west\",\n",
    "            \"sector 21 ulwe, navi mumbai, maharashtra\" : \"sector 21 ulwe\",\n",
    "            \"dombivli, mumbai, maharashtra\" : \"dombivli\",\n",
    "            \"amber enclave - 3rd floor thakurli e, mumbai, maharashtra\" : \"thakurli east\",\n",
    "            \"anath sai apartment, thane, maharashtra\" : \"thane west\",\n",
    "            \"willingdon heights 32nd flr near tardeo rto tulsiwadi, mumbai, maharashtra\" : \"tardeo\",\n",
    "            \"12th floor c2 wing treetops lodha upper thane mankoli bhiwandi thane maharashtra 421302, mumbai, maharashtra\" : \"bhiwandi\",\n",
    "            \"chincholi phatak, mumbai, maharashtra\" : \"malad west\",\n",
    "            \"kanakiya, mumbai, maharashtra\" : \"kandivali east\",\n",
    "            \"puranik hometown kasarvadavli, mumbai, maharashtra\" : \"thane west\",\n",
    "            \"boraivali w 401, mumbai, maharashtra\" : \"borivali west\",\n",
    "            \"prabhadevi, mumbai, maharashtra\" : \"prabhadevi\",\n",
    "            \"green road, thane, maharashtra\" : \"thane west\",\n",
    "            \"lagoona, thane, maharashtra\" : \"thane west\",\n",
    "            \"kasarvadavli, thane, maharashtra\" : \"thane west\",\n",
    "            \"kasarvadavli, thane, maharashtra\" : \"thane west\",\n",
    "            \"dr annie besant road, worli, mumbai, maharashtra 400018, india, mumbai, maharashtra\" : \"worli\",\n",
    "            \"gorai 2, mumbai, maharashtra\" : \"gorai\",\n",
    "            \"lodha casa lakeshore green khoni dombivli, nilje gaon, maharashtra 421204, india, thane, maharashtra\" : \"dombivli east\",\n",
    "            \"diamind garden chembur, mumbai, maharashtra\" : \"chembur\",\n",
    "            \"sector 17 kamothe, navi mumbai, maharashtra\" : \"kamothe\",\n",
    "            \"highland complex, mumbai, maharashtra\" : \"kandivali east\",\n",
    "            \"jerbai wadia road, near tata hospital, parel, mumbai, maharashtra\" : \"parel\",\n",
    "            \"gokhale road, naupada thane, thane, maharashtra\" : \"naupada\",\n",
    "            \"taloja phase 2, navi mumbai, maharashtra\" : \"taloja\",\n",
    "            \"ghansoli sector 11, navi mumbai, maharashtra\" : \"ghansoli\",\n",
    "            \"ramnagar, thane, maharashtra\" : \"thane west\",\n",
    "            \"ram maruti, thane, maharashtra\" : \"thane west\",\n",
    "            \"marine lines, mumbai, maharashtra\" : \"marine lines\",\n",
    "            \"sector 12 vashi., navi mumbai, maharashtra\" : \"sector 12 vashi\",\n",
    "            \"just opposite of mansarovar railway station, navi mumbai, maharashtra\" : \"mansarovar\",\n",
    "            \"bhaskar colony, thane, maharashtra\" : \"thane west\",\n",
    "            \"taloja phase 2, navi mumbai, maharashtra\" : \"taloja\",\n",
    "            \"charkop sector 3charkop gaon, mumbai, maharashtra\" : \"kandivali west\",\n",
    "            \"157, pantnagar, 1st building naidu colony, mumbai, maharashtra\" : \"ghatkopar east\",\n",
    "            \"godrej chandivali, mumbai, maharashtra\" : \"chandivali\",\n",
    "            \"kalwa, thane, thane, maharashtra\" : \"kalwa\",\n",
    "            \"ghansoli, navi mumbai, maharashtra\" : \"ghansoli\",\n",
    "            \"suncity corner seawoodnerul, navi mumbai, maharashtra\" : \"nerul\",\n",
    "            \"lagoona, thane, maharashtra\" : \"dombivli east\",\n",
    "            \"satyam apartment, sector 19, kharghar, navi mumbai, maharashtra\" : \"kharghar\",\n",
    "            \"tilak nagar chembur, mumbai 400089., mumbai, maharashtra\" : \"chembur\",\n",
    "            \"401, sai aakash co op housing society, plot no.23, sector 18, ulwe, navi mumbai, maharashtra\" : \"sector 18 ulwe\",\n",
    "            \"palava casa bella gold, mumbai, maharashtra\" : \"palava\",\n",
    "            \"near vitthal mandir kharigaon kalwa, thane, maharashtra\" : \"kalwa\",\n",
    "            \"kharghar, navi mumbai, maharashtra\" : \"kharghar\",\n",
    "            \"neral karjat, mumbai, maharashtra\" : \"neral\",\n",
    "            \"pahhal avenue, mumbai, maharashtra\" : \"goregaon west\",\n",
    "            \"157, naidu colony, pantnagar, mumbai, maharashtra\" : \"ghatkopar east\",\n",
    "            \"mangalmurthy complex, temghar, thane, maharashtra\" : \"bhiwandi\",\n",
    "            \"plot no b1b, sector 9, airoli navimumbai, mumbai, maharashtra\" : \"sector 9 airoli\",\n",
    "            \"chikhloli jambul phata, thane, maharashtra\" : \"chikhloli\",\n",
    "            \"bapu nagar apartment., thane, maharashtra\" : \"bapu nagar\",\n",
    "            \"crown taloja by lodha, taloja bypass phata, antarli, maharashtra 421204, mumbai, maharashtra\" : \"taloja\",\n",
    "            \"morya garden residency vichumbe, navi mumbai, maharashtra\" : \"new panvel east\",\n",
    "            \"sec-19, navi mumbai, maharashtra\" : \"sector 19 navi mumbai\",\n",
    "            \"siddhivinayak appartment airoli diva koliwada near airoli mulund bridge diva goan gavthan, navi mumbai, maharashtra\" : \"airoli\",  \n",
    "            \"kalher, thane, maharashtra\" : \"kalher\",  \n",
    "            \"vinay nagar, mira road, mumbai, maharashtra\" : \"mira road east\",\n",
    "            \"shree siddhivinayak tower vartaknagar, thane, maharashtra\" : \"vartaknagar\",\n",
    "            \"kasarwadvali godbandar road thane, thane, maharashtra\" : \"kasarwadvali\",  \n",
    "            \"panvel matheran road opp balaji symphony sukapur, navi mumbai, maharashtra\" : \"panvel\",\n",
    "            \"sector 19, shahbaz gaon, cbd belapur, navi mumbai, navi mumbai, maharashtra\" : \"cbd belapur\",\n",
    "            \"gamdevi grant road, mumbai, maharashtra\" : \"gamdevi\",\n",
    "            \"dongri sandhurst road, mumbai, maharashtra\" : \"dongri\",\n",
    "            \"casa rio arebiana, thane, maharashtra\" : \"thane\",\n",
    "            \"lalani dreams residency, village dahivali turfe nid, taluka karjat, mumbai, maharashtra\" : \"karjat\",\n",
    "            \"lodha crown akbar camp road kolshet mumbai maharashtra, mumbai, maharashtra\" : \"kolshet\",  \n",
    "            \"202 sai shruti residency plot c 30 sector 4 khanda colony new panvel 410206, navi mumbai, maharashtra\" : \"new panvel\",  \n",
    "            \"casa milano 12th floor - lodha palava phase 2 dombivali kalyan, navi mumbai, maharashtra\" : \"dombivli\",  \n",
    "            \"203, sunrise glory shilphata near daighar police station, navi mumbai, maharashtra\" : \"shilphata\", \n",
    "            \"dronagiri navi mumbai., mumbai, maharashtra\" : \"dronagiri\",  \n",
    "            \"muthaval, thane, maharashtra\" : \"muthaval\",  \n",
    "            \"sector 5 koperkhairne navi mumbai, navi mumbai, maharashtra\" : \"koperkhairne\",  \n",
    "            \"304, audumber chaya chsl, patilwadi, savarkar nagar, behind thakur college, thane, maharashtra\" : \"thane west\",\n",
    "            \"old panvel near savarkar chowk., navi mumbai, maharashtra\" : \"old panvel\",  \n",
    "            \"opposite j p international school haranwadi naka, mahim road, palghar, palghar, maharashtra\" : \"palghar\",\n",
    "            \"tower 13 2003 runwal gardens dombivali, thane, maharashtra\" : \"dombivli\",\n",
    "            \"village boisar, tal palghar, dist. thane, palghar, maharashtra\" : \"boisar\",  \n",
    "            \"century bazar near chroma showroom, mumbai, maharashtra\" : \"century bazar\",  \n",
    "            \"d/305., palghar, maharashtra\" : \"palghar\",  \n",
    "            \"e 2 303 gaurav citymira road area, mumbai, maharashtra\" : \"mira road east\",\n",
    "            \"umiya darshan chs, nerul sec 50 new, navi mumbaiseawoods, navi mumbai, maharashtra\" : \"seawoods\",  \n",
    "            \"rambhau mhalgi marg, besides shrushti residency, khambalpada, thakurli e, dombivli e, thane, maharashtra\" : \"thakurli east\",\n",
    "            \"ramabai paradise opp garden city tawor mira road thane, mumbai, maharashtra\" : \"mira road\",  \n",
    "            \"siddhivinayak florentia garden citymira bhayandar, mumbai, maharashtra\" : \"mira bhayandar\",  \n",
    "            \"bonkode sector 12, navi mumbai, maharashtra\" : \"sector 12 bonkode\",  \n",
    "            \"vasant villa, padmavati devi marg, iit market, powai, mumbai 400076, mumbai, maharashtra\" : \"powai\",  \n",
    "            \"novapark co opp housing society ltd flat no 303 plot no 68., navi mumbai, maharashtra\" : \"navi mumbai\",\n",
    "            \"mira road area, mumbai, maharashtra\" : \"mira road\",  \n",
    "            \"near divya heights in sector 26 navi mumbai, navi mumbai, maharashtra\" : \"sector 26 navi mumbai\",\n",
    "            \"ganesh nagar, near boisar railway starion, palghar, maharashtra\" : \"boisar\",  \n",
    "            \"c-001 nand dham building kashimira mira road, mumbai, maharashtra\" : \"mira road east\",\n",
    "            \"om sankalp chs, kopar road, thane 421202, thane, maharashtra\" : \"dombivli west\",\n",
    "            \"svarna kojagiri, mumbai, maharashtra\" : \"goregaon east\",\n",
    "            \"unique aurum, poonam garden, thane, maharashtra\" : \"mira road east\",\n",
    "            \"neelkanth darshan society b-203125a near hotel panvel palaceold panvel, mumbai, maharashtra\" : \"old panvel\",\n",
    "            \"mira road kanakia, thane, maharashtra\" : \"mira road east\",\n",
    "            \"panvel, navi mumbai, navi mumbai, maharashtra\" : \"navi mumbai\",\n",
    "            \"chitalsar manpada, thane, maharashtra\" : \"manpada\",  \n",
    "            \"near raj kamal studio, parel, mumbai, maharashtra\" : \"parel\",  \n",
    "            \"nilje station road, nilje, thane, maharashtra\" : \"nilje\", \n",
    "            \"flat no-604, plot no-4, sector 14, taloja, navi mumbai, maharashtra\" : \"taloja\",  \n",
    "            \"jethe tower, 701, ambawadi, opp. ambawadi bus stop, borivali e. mumbai-400068, mumbai, maharashtra\" : \"borivali east\",  \n",
    "            \"lodha crown viva, flat 1006, 10th flr tower 5, majiwada, thane, mumbai, maharashtra\" : \"majiwada\",  \n",
    "            \"sunbeam heritage hsg soc, sector 4c, khanda colony asudgoan panvel, navi mumbai, maharashtra\" : \"panvel\",\n",
    "            \"lodha upper thane, treetops, thane, maharashtra\" : \"upper thane\",  \n",
    "            \"aanandi park a101 behind ganapati mandir durgesh park kalher bhiwandi, thane, maharashtra\" : \"kalher\",  \n",
    "            \"a-9/201 tejaswi apt, near st. thomas church, sai baba nagar, mira road., mumbai, maharashtra\" : \"mira road east\",\n",
    "            \"sector 11, next to miraj cinema, navi mumbai, maharashtra\" : \"sector 11\",\n",
    "            \"aster, regency anantham, dombivli, mumbai, maharashtra\" : \"dombivli\",  \n",
    "            \"chand nagar, near baba medical, thane, maharashtra\" : \"thane\", \n",
    "            \"thane majiwada lodha complex opp-water tank, thane, maharashtra\" : \"majiwada\",  \n",
    "            \"near kalidas natyamamdir, mumbai, maharashtra\" : \"mulund west\",\n",
    "            \"badlapur, thane, maharashtra\" : \"badlapur\",  \n",
    "            \"near mittal club, palghar, maharashtra\" : \"palghar\",  \n",
    "            \"shree krupa apt flat no 102 plot144145 sector10 new panvel navi mumbai, navi mumbai, maharashtra\" : \"new panvel\",  \n",
    "            \"sector 20, cbd belapur opp bank of india  park, adjacent to hansraj building, navi mumbai, maharashtra\" : \"sector 20 cbd belapur\",  \n",
    "            \"brahmand patlipada link road, opp tulsi hotel, thane, maharashtra\" : \"thane\",  \n",
    "            \"gurukiran socity airoli sector 30 gothavali, navi mumbai, maharashtra\" : \"sector 30 gothavali\"}\n",
    "    \n",
    "    # Fill \"location\" based on \"address\" matching mapping dictionary\n",
    "    df.loc[df[\"location\"].isna(), \"location\"] = df[\"address\"].map(mapping)\n",
    "\n",
    "    # Mapping dictionary\n",
    "    replace_dict = {\n",
    "        \"bhayander\": \"bhayandar\",\n",
    "        \"century Bazar\": \"century bazaar\",\n",
    "        \"dombivali\": \"dombivli\",\n",
    "        \"kasarwadvali\": \"kasarvadavali\",\n",
    "        \"koparkhairane\": \"kopar khairane\",\n",
    "        \"koparkhairne\": \"kopar khairane\",\n",
    "        \"koperkhairne\": \"kopar khairane\",\n",
    "        \"koperkhairane\": \"kopar khairane\",\n",
    "        \"koperkharine\": \"kopar khairane\",\n",
    "        \"mulund goregaon link road\": \"goregaon mulund link road\",\n",
    "        \"naigoan\": \"naigaon\",\n",
    "        \"nalasopara\": \"nala sopara\",\n",
    "        \"nallasopara\": \"nala sopara\",\n",
    "        \"palaspe phata\": \"palaspa\",\n",
    "        \"palava\": \"palava city\",\n",
    "        \"shil phata\": \"shilphata\",\n",
    "        \"vartaknagar\": \"vartak nagar\",\n",
    "        \"vileparle\": \"vile parle\",\n",
    "        \"4 east\": \"ulhasnagar\",\n",
    "        \"402borivali west\": \"borivali west\",\n",
    "        \"adai\": \"adai navi mumbai\"  # Careful with this if \"adai\" alone is meant to be corrected\n",
    "    }\n",
    "    \n",
    "    # Function to apply mapping\n",
    "    def correct_location(location):\n",
    "        for wrong, correct in replace_dict.items():\n",
    "            if pd.notnull(location) and wrong.lower() in location.lower():\n",
    "                # Replace wrong word with correct one (case-insensitive)\n",
    "                location = location.lower().replace(wrong.lower(), correct.lower())\n",
    "        return location\n",
    "    \n",
    "    # Apply correction function\n",
    "    df['location'] = df['location'].apply(correct_location)\n",
    "\n",
    "    location_mapping = {\n",
    "        \"mulund airoli road\": \"navi mumbai\",\n",
    "        \"taloja bypass road\": \"navi mumbai\",\n",
    "        \"panvel\": \"navi mumbai\",\n",
    "        \"sector 9 airoli\": \"navi mumbai\",\n",
    "        \"taloja\": \"navi mumbai\",\n",
    "        \"old panvel\": \"navi mumbai\",\n",
    "        \"naigaon east vasai link road\": \"palghar\",\n",
    "        \"naigaon palghar\": \"palghar\",\n",
    "        \"vasai\": \"palghar\",\n",
    "        \"vasai east\": \"palghar\",\n",
    "        \"vasai road west\": \"palghar\",\n",
    "        \"vasai west\": \"palghar\",\n",
    "        \"virar\": \"palghar\",\n",
    "        \"virar east\": \"palghar\",\n",
    "        \"virar west\": \"palghar\",\n",
    "        \"thane west\": \"thane\",\n",
    "        \"kolshet\": \"thane\",\n",
    "        \"majiwada\": \"thane\",\n",
    "        \"kandivali east\": \"mumbai\",\n",
    "        \"thane belapur road\": \"thane\",\n",
    "        \"mahim\": \"mumbai\",\n",
    "        \"bhayandar\": \"thane\",\n",
    "        \"bhayandar east\": \"thane\",\n",
    "        \"bhayandar west\": \"thane\",\n",
    "        \"bhayandarpada\": \"thane\",\n",
    "        \"mira bhayandar\": \"thane\",\n",
    "        \"mira bhayandar road\": \"thane\",\n",
    "        \"mira road\": \"thane\",\n",
    "        \"mira road area\": \"thane\",\n",
    "        \"mira road east\": \"thane\",\n",
    "        \"nala sopara\": \"palghar\",\n",
    "        \"naigaon east\": \"palghar\",\n",
    "        \"naigaon west\": \"palghar\",\n",
    "        \"nala sopara east\": \"palghar\",\n",
    "        \"nala sopara west\": \"palghar\",\n",
    "        \"kharghar\": \"navi mumbai\"\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Update city based on location presence\n",
    "    for key, value in location_mapping.items():\n",
    "        df.loc[df[\"location\"].str.contains(key, case=False, na=False), \"city\"] = value\n",
    "\n",
    "    df['location'] = df['location'].replace('', np.nan)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # property_type : New property, Resale, Rent, Other\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['property_type'] = df[\"many_transaction type\"].combine_first(df[\"leftmany_transaction type\"])\n",
    "\n",
    "    df = df[~df['property_type'].isin(['other', 'rent'])]\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # ownership\n",
    "    df = df.rename(columns={'md_type of ownership': 'ownership'})\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #status\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['status'] = df['many_status'].combine_first(df['leftmany_status'])\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #construction\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['construction_1'] = df['many_age of construction'].combine_first(df['leftmany_age of construction'])\n",
    "\n",
    "    df = df.rename(columns={'md_age of construction': 'construction'})\n",
    "\n",
    "    df['construction'] = df.apply(\n",
    "        lambda row: 'under construction' if row['status'] == 'under construction' else row['construction'], axis=1\n",
    "    )\n",
    "\n",
    "    df['status'] = df.apply(\n",
    "        lambda row: 'under construction' if row['construction'] == 'under construction' else row['status'], axis=1\n",
    "    )\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #extra rooms \n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['balcony1'] = df['leftmany_additional rooms'].combine_first(df['many_additional rooms'])\n",
    "    \n",
    "    df['extra_room'] = df['balcony1'].str.split(' ').str[1].str.strip()\n",
    "    \n",
    "    result = df['extra_room'].apply(\n",
    "        lambda x: any(str(x) in str(room) for room in df['md_additional rooms']) if pd.notnull(x) else False\n",
    "    )\n",
    "    \n",
    "    #sort value alphabetically \n",
    "    df['extra_rooms'] = df['md_additional rooms'].apply(\n",
    "        lambda x: ', '.join(sorted(x.split(', '))) if pd.notna(x) else None\n",
    "    )\n",
    "    \n",
    "    #remove none of these eg:from these 'none of these, store' and keep only store \n",
    "    #but if we have only 'none of these' then we keep that as it is \n",
    "    #also remove room word from all values \n",
    "    \n",
    "    df['extra_rooms'] = df['md_additional rooms'].apply(\n",
    "        lambda x: x if pd.isna(x) or str(x).strip() == 'none of these' else ', '.join(\n",
    "            [item.replace(' room', '') for item in str(x).split(', ') if item != 'none of these']\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Facing\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['facing'] = df['leftmany_facing'].combine_first(df['many_facing'])\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #towers and available_units\n",
    "    df = df.rename(columns={'aboutpjt_total units': 'available_units', \n",
    "                        'aboutpjt_total towers': 'towers'})\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #seller\n",
    "    df['seller'] = df['potentialaction'].str.split(',').str[1].str.split(':').str[2].str.strip(\" '\\\"\")\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #price_category\n",
    "    # Define price bins and labels\n",
    "    price_bins = [0, 0.99, 1.99, 2.99, 3.99, 4.99, 5.99, 6.99, 7.99, 8.99, 9.99, 14.99, 20.00, float('inf')]\n",
    "    price_labels = [\n",
    "        \"0.00 - 0.99\", \"1.00 - 1.99\", \"2.00 - 2.99\", \"3.00 - 3.99\", \"4.00 - 4.99\", \n",
    "        \"5.00 - 5.99\", \"6.00 - 6.99\", \"7.00 - 7.99\", \"8.00 - 8.99\", \"9.00 - 9.99\", \n",
    "        \"10.00 - 14.99\", \"15.00 - 20.00\", \"20.00 and above\"\n",
    "    ]\n",
    "    \n",
    "    # Use pd.cut to categorize the prices\n",
    "    df['price_category'] = pd.cut(df['price'], bins=price_bins, labels=price_labels, right=True)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #overlooking\n",
    "    df['overlooking'] = df['md_overlooking'].apply(\n",
    "        lambda x: ', '.join(sorted(map(str.strip, x.split(',')))) if pd.notna(x) else np.nan\n",
    "    )\n",
    "    \n",
    "    # Remove the phrase 'not available' from the 'overlooking' column\n",
    "    df['overlooking'] = df['overlooking'].str.replace(',? *not available', '', regex=True)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #room_type\n",
    "    df['room_type'] = df['name'].apply(lambda x: 'flat' if 'flat' in x else ('apartment' if 'apartment' in x else 'other'))\n",
    "\n",
    "    #drop apartment rows\n",
    "    df = df[df['room_type'] != 'apartment']\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #nearby_location_km\n",
    "\n",
    "    # Reusable function\n",
    "    def combine_columns(df, cols, new_col):\n",
    "        df[new_col] = df[cols].apply(lambda row: ', '.join(filter(pd.notna, row)), axis=1)\n",
    "    \n",
    "    # Education\n",
    "    combine_columns(df, [\n",
    "        'educational institute_1', 'educational institute_2', \n",
    "        'educational institute_3', 'educational institute_4', \n",
    "        'educational institute_5'\n",
    "    ], 'education')\n",
    "    \n",
    "    # Transport\n",
    "    combine_columns(df, [\n",
    "        'transportation hub_1', 'transportation hub_2', \n",
    "        'transportation hub_3', 'transportation hub_4', \n",
    "        'transportation hub_5'\n",
    "    ], 'transport')\n",
    "    \n",
    "    # Shopping Centre\n",
    "    combine_columns(df, [\n",
    "        'shopping centre_1', 'shopping centre_2', \n",
    "        'shopping centre_3', 'shopping centre_4', \n",
    "        'shopping centre_5'\n",
    "    ], 'shopping_centre')\n",
    "    \n",
    "    # Commercial Hub\n",
    "    combine_columns(df, [\n",
    "        'commercial hub_1', 'commercial hub_2', \n",
    "        'commercial hub_3', 'commercial hub_4', \n",
    "        'commercial hub_5'\n",
    "    ], 'commercial_hub')\n",
    "    \n",
    "    # Hospital\n",
    "    combine_columns(df, [\n",
    "        'hospital_1', 'hospital_2', \n",
    "        'hospital_3', 'hospital_4', \n",
    "        'hospital_5'\n",
    "    ], 'hospital')\n",
    "    \n",
    "    # Tourist\n",
    "    combine_columns(df, [\n",
    "        'tourist spot_1', 'tourist spot_2', \n",
    "        'tourist spot_3', 'tourist spot_4'\n",
    "    ], 'tourist')\n",
    "\n",
    "    # Function to extract mean km from text\n",
    "    # Initialize global zero counter\n",
    "    #zero_count = 0\n",
    "    \n",
    "    # Function to extract mean km with zero replacement\n",
    "    def extract_mean_km(text):\n",
    "        #global zero_count\n",
    "        if pd.isna(text):\n",
    "            return np.nan\n",
    "        km_values = [float(x) for x in re.findall(r'([\\d.]+)\\s*km', text)]\n",
    "        if any(km == 0.0 for km in km_values):\n",
    "            #zero_count += 1\n",
    "            km_values = [0.0001 if km == 0.0 else km for km in km_values] #reason for this code given below \n",
    "        return sum(km_values) / len(km_values) if km_values else np.nan\n",
    "    \n",
    "    # Function to extract min km with zero replacement\n",
    "    def extract_min_km(text):\n",
    "        if pd.isna(text):\n",
    "            return np.nan\n",
    "        km_values = [float(x) for x in re.findall(r'([\\d.]+)\\s*km', text)]\n",
    "        km_values = [0.0001 if km == 0.0 else km for km in km_values]\n",
    "        return min(km_values) if km_values else np.nan\n",
    "    \n",
    "    # Apply to column\n",
    "    df['education_mean_km'] = df['education'].apply(extract_mean_km)\n",
    "    df['education_min_km'] = df['education'].apply(extract_min_km)\n",
    "    \n",
    "    # Print your zero count!\n",
    "    #print(f\"\\nRows containing zero km replaced: {zero_count}\") #print no of zero km values in data , \n",
    "                                                                #means something which is in zero km , like hospital in building so it become zero km\n",
    "                                                                #for such data make 0.0001 km just make identify them as there is location of hospital or any other \n",
    "                                                                #if we keep 0 km only then it may means that there is no location for that property \n",
    "                                                                #if any there is hospital location which is inside building or something then it become 0.0 km so this get counut as 1\n",
    "                                                                #in hospital_within_2km\n",
    "    \n",
    "    \n",
    "    # Function to count places within 2 km\n",
    "    #so one row has so many values and from that how many are within 2km that we count here\n",
    "    #eg: [1.0,3.0,1.9,4.8] so here it is 2\n",
    "    def count_within_2km(text):\n",
    "        if pd.isna(text):\n",
    "            return np.nan\n",
    "        km_values = [float(x) for x in re.findall(r'([\\d.]+)\\s*km', text)]\n",
    "        return sum(1 for km in km_values if km <= 2.0)\n",
    "    \n",
    "    # List of combined location columns\n",
    "    location_cols = ['education', 'transport', 'shopping_centre', 'commercial_hub', 'hospital', 'tourist']\n",
    "    \n",
    "    # Apply all 3 functions: mean, min, within_2km\n",
    "    for col in location_cols:\n",
    "        df[col + '_mean_km'] = df[col].apply(extract_mean_km)\n",
    "        df[col + '_min_km'] = df[col].apply(extract_min_km)\n",
    "        df[col + '_within_2km'] = df[col].apply(count_within_2km)\n",
    "    \n",
    "    # Show only mean and min columns\n",
    "    mean_cols = [col + '_mean_km' for col in location_cols]\n",
    "    min_cols = [col + '_min_km' for col in location_cols]\n",
    "    within_2km_cols = [col + '_within_2km' for col in location_cols]\n",
    "    \n",
    "    # Add final 5 summary columns\n",
    "    df['overall_min_mean_km'] = df[mean_cols].min(axis=1)\n",
    "    df['overall_avg_mean_km'] = df[mean_cols].mean(axis=1)\n",
    "    df['overall_min_min_km'] = df[min_cols].min(axis=1)\n",
    "    df['overall_avg_min_km'] = df[min_cols].mean(axis=1)\n",
    "    df['total_within_2km'] = df[within_2km_cols].sum(axis=1) #sum of all within_2km location_cols\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #flooring\n",
    "    df = df.rename(columns={'md_flooring':'flooring'})\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #amenities\n",
    "    # Select columns that start with 'am_' and include 'id'\n",
    "    am_cols = ['id'] + [col for col in df.columns if col.startswith('am_')]\n",
    "    \n",
    "    # Create a separate DataFrame with those columns\n",
    "    am_df = df[am_cols].copy()\n",
    "    \n",
    "    # Drop 'am_' columns from the original DataFrame (keep 'id')\n",
    "    df = df.drop(columns=[col for col in df.columns if col.startswith('am_')])\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #Custom data corrections and row-level cleaning\n",
    "\n",
    "    # List of IDs to remove\n",
    "    ids_to_remove = [\n",
    "        'cardid70421965',  \n",
    "        'cardid71698587',\n",
    "        'cardid41440251',\n",
    "        'cardid70017925',  \n",
    "        'cardid73050463',\n",
    "        'cardid49131617',\n",
    "        'cardid72273473',\n",
    "        'cardid66762427',\n",
    "        'cardid70615879',\n",
    "        'cardid72819785',\n",
    "        'cardid71143703',\n",
    "        'cardid72821117',\n",
    "        'cardid72884955',\n",
    "        'cardid72803713',\n",
    "        'cardid73037481',\n",
    "        'cardid69783235',\n",
    "        'cardid73144165',\n",
    "        'cardid33966233',\n",
    "        'cardid73046249',\n",
    "        'cardid69702399',\n",
    "        'cardid54078457',\n",
    "        'cardid71697753'\n",
    "    ]\n",
    "    \n",
    "    # Drop rows with matching IDs\n",
    "    df = df[~df['id'].isin(ids_to_remove)].reset_index(drop=True)\n",
    "    \n",
    "    #after observation \n",
    "    ids_to_update = ['cardid73059851', 'cardid72926775', 'cardid58806131']\n",
    "    \n",
    "    df.loc[df['id'].isin(ids_to_update), 'city'] = 'palghar'\n",
    "    df.loc[df['id'].isin(ids_to_update), 'location'] = 'palghar'\n",
    "    \n",
    "    #assign 'thane' to the city for all rows where location is 'ulhasnagar'\n",
    "    df.loc[df['location'] == 'ulhasnagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'agashi', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'bhabola', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'bolinj', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'diwanman', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'dongarpada road', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'evershine city', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'juchandra', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'morya nagar', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'oswal nagari', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'padmavati nagar bolinj', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'unique garden', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'rustomjee global city', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'wagholi', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'vinay nagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'yashwanth nagar', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'dongarpada', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'beverly park', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'padrikhan wadi', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'medetiya nagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'hatkesh udhog nagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'kashigaon', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'kashimira', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'sector 8 shanti nagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'shanti vihar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'chulne', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'mahajan wadi', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'sector 9 shanti nagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'chandan shanti', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'pleasant park', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'sector 3 shanti nagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'poonam sagar complex', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'stella', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'ramdev park', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'golden nest phase 1', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'madhuban township', 'city'] = 'palghar'\n",
    "    \n",
    "    # Update city to 'thane' where address starts with 'mira' (case insensitive)\n",
    "    df.loc[df['address'].str.lower().str.startswith('mira', na=False), 'city'] = 'thane'\n",
    "    \n",
    "    #make thane in city for all this ids\n",
    "    ids_to_update = [\n",
    "        \"cardid72703033\",\n",
    "        \"cardid69846363\",\n",
    "        \"cardid73257889\",\n",
    "        \"cardid56191653\",\n",
    "        \"cardid72796607\",\n",
    "        \"cardid73026297\",\n",
    "        \"cardid72794677\",\n",
    "        \"cardid66964031\",\n",
    "        \"cardid58541153\",\n",
    "        \"cardid73076791\",\n",
    "        \"cardid72794677\",\n",
    "        \"cardid53323155\",\n",
    "        \"cardid69812109\",\n",
    "        \"cardid69665873\",\n",
    "        \"cardid70673145\",\n",
    "        \"cardid70120173\",\n",
    "        \"cardid60101171\",\n",
    "        \"cardid73012265\",\n",
    "        \"cardid73028981\",\n",
    "        \"cardid71481487\",\n",
    "        \"cardid67617413\",\n",
    "        \"cardid53977959\"\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    df.loc[df['id'].isin(ids_to_update), 'city'] = 'thane'\n",
    "    \n",
    "    #make palghar in city for all this ids\n",
    "    ids_to_update = [\n",
    "        \"cardid72923721\",\n",
    "        \"cardid61647785\",\n",
    "        \"cardid70476757\",\n",
    "        \"cardid72179863\",\n",
    "        \"cardid72846389\",\n",
    "        \"cardid73127129\",\n",
    "        \"cardid61883771\",\n",
    "        \"cardid72998493\",\n",
    "        \"cardid73114181\",\n",
    "        \"cardid71923233\",\n",
    "        \"cardid63887703\",\n",
    "        \"cardid72831163\"\n",
    "    ]\n",
    "    \n",
    "    df.loc[df['id'].isin(ids_to_update), 'city'] = 'palghar'\n",
    "    \n",
    "    #make navi mumbai in city for all this ids\n",
    "    ids_to_update = [\n",
    "        \"cardid62724753\"\n",
    "    ]\n",
    "    \n",
    "    df.loc[df['id'].isin(ids_to_update), 'city'] = 'navi mumbai'\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    # Create a mask for rows where 'lattitude' starts with 16, 12, or 9\n",
    "    mask = (\n",
    "        df['lattitude'].astype(str).str.startswith('16') |\n",
    "        df['lattitude'].astype(str).str.startswith('12') |\n",
    "        df['lattitude'].astype(str).str.startswith('9')\n",
    "    )\n",
    "    \n",
    "    # Replace only 'lattitude' and 'longitude' with NaN for those rows\n",
    "    df.loc[mask, ['lattitude', 'longitude']] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #drop columns\n",
    "    df.drop(['numberofrooms','bb_beds','leftbb_beds','bb_bed','leftbb_bed','multi_bed_filled','bb_baths','leftbb_baths','bb_bath','leftbb_bath','multi_bath_filled',\n",
    "             'bb_covered-parking','leftbb_covered-parking','many_car parking','leftmany_car parking','md_price breakup','property_loc','many_transaction type',\n",
    "             'leftmany_transaction type','many_type of ownership','leftmany_type of ownership','many_status', 'leftmany_status','many_lifts','md_lift','leftmany_lifts',\n",
    "             'many_lift','leftmany_lift','multi_lift_filled','aboutpjt_total floors','floor_work_1','many_floor','leftmany_floor','md_floors allowed for construction',\n",
    "             'construction_1','many_age of construction','leftmany_age of construction','bb_balcony', 'leftbb_balcony', 'bb_balconies','leftbb_balconies',\n",
    "             'leftmany_additional rooms', 'balcony1', 'many_additional rooms','extra_room', 'md_additional rooms','leftmany_facing','many_facing','ap_unit','ap_tower',\n",
    "             'ap_tower & unit','geo','potentialaction','md_overlooking','room_type','aboutpjt_project size','educational institute_1','educational institute_2',\n",
    "             'educational institute_3','educational institute_4','educational institute_5','transportation hub_1','transportation hub_2','transportation hub_3',\n",
    "             'transportation hub_4','transportation hub_5','shopping centre_1','shopping centre_2','shopping centre_3','shopping centre_4','shopping centre_5',\n",
    "             'commercial hub_1','commercial hub_2','commercial hub_3','commercial hub_4','commercial hub_5','hospital_1','hospital_2','hospital_3','hospital_4','hospital_5',\n",
    "             'tourist spot_1','tourist spot_2','tourist spot_3','tourist spot_4','education', 'transport', 'shopping_centre', 'commercial_hub', 'hospital', 'tourist',\n",
    "             'url','image','image_urls','name','wholeaddress','address','locality_rank', 'locality_url_rating'\n",
    "            ],axis=1,inplace=True)\n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "    return df,am_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "\n",
    "    # Go up 3 levels: notebooks/ -> py files-vscode/ -> PROPERTY_PROJECT/\n",
    "    root_path = Path(__file__).parent.parent.parent\n",
    "\n",
    "    data_load_path = root_path / \"data\" / \"f_original magicbricks cleaned 12022 data.csv\"\n",
    "\n",
    "    print(\"Loading data from:\", data_load_path)\n",
    "    df = pd.read_csv(data_load_path)\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    # Call your cleaning function\n",
    "    from vs_property_data_cleaning_utils import basic_cleaning  # if needed\n",
    "    cleaned_df, am_df = basic_cleaning(df)\n",
    "\n",
    "    # Save the cleaned data\n",
    "    cleaned_df.to_csv(root_path / \"files_vscode\" / \"data\" / \"py_cleaned_data.csv\", index=False)\n",
    "    print(\"Data cleaned and saved to py_cleaned_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1112f43a-2cd1-43ef-bc52-d600d9b4cc63",
   "metadata": {},
   "source": [
    "correct vs code 2   \n",
    "this below code where i added this 4 columns removal from \"4.property_missingness_identification\"  \n",
    "and in this below code i have merge df and am_df becoz this is correct approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42011d36-2161-4ead-b332-3d451bf5bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "import ast\n",
    "\n",
    "\n",
    "def load_data(data_path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df\n",
    "\n",
    "def basic_cleaning(data : pd.DataFrame):\n",
    "    df = data.copy()\n",
    "    \n",
    "    #convert column names into lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    #drop unwanted columns\n",
    "    df.drop(['@id','@type','bhk_type' ,'locality_url','md_booking amount','md_loan offered','md_water availability','ap_price','ap_price per sqft','ap_configuration',\n",
    "              'ap_pjt_url','ap_ratings','ap_reviews_by','headings_with_ratings','aboutpjt_bhk','2 bhk flat','locality_url_review','liv_environment','liv_commuting',\n",
    "              'liv_places of interest','md_status of electricity','3 bhk flat','1 bhk flat','studio apartment','4 bhk flat','5 bhk flat','md_landmarks', \n",
    "              'multistorey apartment', '3 bhk villa', '4 bhk villa', 'residential plot', '2 bhk builder', '3 bhk builder','4 bhk penthouse','5 bhk penthouse', \n",
    "              'md_authority approval','6 bhk flat','rent','commercial office space','3 bhk penthouse','md_rera id','aboutpjt_launch date'],axis=1,inplace=True)\n",
    "    \n",
    "    #drop duplicate rows\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    #delete column which have all nan values\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "    df[df.select_dtypes('object').columns] = df.select_dtypes('object').apply(\n",
    "        lambda col: col.map(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "    )\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #function 1\n",
    "    def check_more_than_one_value_in_column(df, cols, new_col_name, col_name):\n",
    "        # Step 1: Create a boolean column to check if more than one value (non-NaN) is filled in the specified columns\n",
    "        df[new_col_name] = df[cols].notna().sum(axis=1) > 1\n",
    "    \n",
    "        # Step 2: Combine all values from the specified columns into a list for each row\n",
    "        def combine_values():\n",
    "            df[col_name] = [list(values) for values in zip(*[df[col] for col in cols])]\n",
    "    \n",
    "        combine_values()\n",
    "    \n",
    "        found_distinct = False\n",
    "    \n",
    "        # Step 3: If any row has more than one value\n",
    "        if df[new_col_name].any():\n",
    "            for index, row in df[col_name].items():\n",
    "                non_nan_vals = [val for val in row if pd.notna(val)]\n",
    "                # Step 4: If more than one unique value found in the row, print that row\n",
    "                if len(set(non_nan_vals)) > 1: #take rows which have more than one unique value \n",
    "                    print(f\"Row {index} has multiple distinct non-NaN values: {row}\") \n",
    "                    found_distinct = True  #if get more than 1 distinct value then below thing wont run\n",
    "    \n",
    "        # Step 5: If no row has more than one unique value, safely pick the first non-NaN value\n",
    "        if not found_distinct:\n",
    "            df[col_name] = df[col_name].apply(lambda row: next((val for val in row if pd.notna(val)), None))\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #function2\n",
    "    def combine_first_valid(df, source_cols, new_col_name):\n",
    "        \"\"\"\n",
    "        Create a new column with the first valid (non-null, non-'nan', non-empty) value \n",
    "        across the specified source columns.\n",
    "        \"\"\"\n",
    "        # Combine columns into new_col_name using first valid value per row\n",
    "        df[new_col_name] = df[source_cols].apply(\n",
    "            lambda row: next(\n",
    "                (str(x) for x in row if pd.notna(x) and str(x).strip().lower() != 'nan' and str(x).strip() != ''),\n",
    "                np.nan\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Normalize the new column's casing and whitespace\n",
    "        df[new_col_name] = df[new_col_name].str.strip().str.lower()\n",
    "    \n",
    "        # Drop the source columns\n",
    "        df.drop(columns=source_cols, inplace=True)\n",
    "    \n",
    "        return df\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #emi\n",
    "    converted_emi = []\n",
    "\n",
    "    for emi_n in df['emi']:\n",
    "        if isinstance(emi_n, str):  # Check if emi_n is a string\n",
    "            if 'k' in emi_n:\n",
    "                # Convert from thousands to lakhs\n",
    "                converted_emi.append(float(emi_n.replace('k', '')) / 100)\n",
    "            elif 'l' in emi_n:\n",
    "                # No change needed for lakhs\n",
    "                converted_emi.append(float(emi_n.replace('l', '')))\n",
    "            else:\n",
    "                # Convert rupees to lakhs\n",
    "                converted_emi.append(float(emi_n) / 100000)\n",
    "        else:\n",
    "            # If it's already a float, convert rupees to lakhs\n",
    "            converted_emi.append(emi_n / 100000)\n",
    "    \n",
    "    # Add the converted values to the DataFrame\n",
    "    df['converted_emi'] = converted_emi\n",
    "    df = df.drop(['emi'], axis=1)\n",
    "    df.rename(columns={'converted_emi': 'emi'}, inplace=True)\n",
    "        \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # numerical column\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #price\n",
    "    def convert_price_to_cr(val):\n",
    "        if isinstance(val, str):  # check if value is a string\n",
    "            parts = val.replace('₹', '').split()  # remove ₹ and split into amount and unit\n",
    "            if len(parts) == 2:  # ensure both amount and unit exist\n",
    "                amount, unit = parts\n",
    "                amount = float(amount)  \n",
    "                return amount / 100 if unit.lower() == 'lac' else amount  # convert lac to Cr\n",
    "        return None  # return None if invalid\n",
    "    \n",
    "    # Apply conversion\n",
    "    df['price'] = df['price'].apply(convert_price_to_cr)\n",
    "\n",
    "    #datatype to float\n",
    "    df['price'] = df['price'].astype('float64')\n",
    "    \n",
    "    # Drop rows with missing prices\n",
    "    df = df.dropna(subset=['price'])\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #bed\n",
    "    check_more_than_one_value_in_column(df, ['numberofrooms', 'bb_beds', 'leftbb_beds', 'bb_bed','leftbb_bed'], 'multi_bed_filled','bed')  \n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #bath\n",
    "    check_more_than_one_value_in_column(df, ['bb_baths', 'leftbb_baths', 'bb_bath', 'leftbb_bath'], 'multi_bath_filled','bath')  \n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #parking\n",
    "    # Convert 'leftmany_car parking' into sum of all digits\n",
    "    df['leftmany_car parking'] = df['leftmany_car parking'].apply(\n",
    "        lambda x: sum(map(int, re.findall(r'\\d+', str(x)))) if pd.notna(x) else np.nan\n",
    "    )\n",
    "    \n",
    "    # Convert 'many_car parking' into sum of all digits\n",
    "    df['many_car parking'] = df['many_car parking'].apply(\n",
    "        lambda x: sum(map(int, re.findall(r'\\d+', str(x)))) if pd.notna(x) else np.nan\n",
    "    )\n",
    "    \n",
    "    # Take max across the four parking columns\n",
    "    df['parking'] = df[\n",
    "        ['bb_covered-parking', 'leftbb_covered-parking', 'many_car parking', 'leftmany_car parking']\n",
    "    ].apply(\n",
    "        lambda row: np.nanmax(row.values) if pd.notna(row).any() else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #area and costpersqft     \n",
    "\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['area_work'] = df[\"many_carpet area\"].combine_first(df[\"leftmany_carpet area\"])\n",
    "\n",
    "\n",
    "    # Extract carpet area features\n",
    "    df[\"carpet_area\"] = df[\"area_work\"].apply(lambda x: float(re.match(r'([\\d,\\.]+)', x).group(1).replace(',', '')) if pd.notna(x) and re.match(r'^[\\d,\\.]+', x) else None) \n",
    "    df['cost_per_sqft'] = df['area_work'].str.extract(r'₹([\\d,\\.]+)')[0].str.replace(',', '').astype(float)\n",
    "    df['area_unit'] = df['area_work'].str.extract(r'/([^/]+)$')\n",
    "    \n",
    "    # Remove unwanted area units\n",
    "    df = df[~df['area_unit'].isin(['sqm', 'kanal'])]\n",
    "    \n",
    "    # Combine super built-up area\n",
    "    df['super_build_area_work'] = df[\"leftmany_super built-up area\"].combine_first(df[\"many_super built-up area\"])\n",
    "    \n",
    "    \n",
    "    # Extract super built-up features\n",
    "    df['initial_unit'] = df['super_build_area_work'].apply(lambda x: ''.join([char for char in str(x)[re.match(r'\\d+', str(x)).end():] if char.isalpha()])[:4] if isinstance(x, str) else None)\n",
    "    df = df[~df['initial_unit'].isin(['sqms', 'sqyr'])]\n",
    "    df[\"super_build_up_area\"] = df[\"super_build_area_work\"].apply(lambda x: float(re.match(r'([\\d,\\.]+)', x).group(1).replace(',', '')) if pd.notna(x) and re.match(r'^[\\d,\\.]+', x) else None)\n",
    "    df['super_build_up_cost_per_sqft'] = df['super_build_area_work'].str.extract(r'₹([\\d,\\.]+)')[0].str.replace(',', '').astype(float)\n",
    "    df['super_built_up_area_unit'] = df['super_build_area_work'].str.extract(r'/([^/]+)$')\n",
    "    \n",
    "    # Final feature selection with combine_first\n",
    "    df['f_area'] = df[\"carpet_area\"].combine_first(df[\"super_build_up_area\"])\n",
    "    df['f_costpersqft'] = df[\"cost_per_sqft\"].combine_first(df[\"super_build_up_cost_per_sqft\"])\n",
    "    df['f_area_unit'] = df[\"super_built_up_area_unit\"].combine_first(df[\"area_unit\"])\n",
    "    df['f_area'] = df['f_area'].astype('float')\n",
    "    df['f_costpersqft'] = df['f_costpersqft'].astype('float')\n",
    "    \n",
    "    \n",
    "    # Fill missing values from 'area' column\n",
    "    df['dupli_f_area'] = np.where(\n",
    "        pd.isna(df['f_area']) & pd.notna(df['area']),\n",
    "        df['area'].str.extract(r'([\\d,\\.]+)')[0].str.replace(',', '').astype(float),\n",
    "        None\n",
    "    )\n",
    "    \n",
    "    df['dupli_f_area_unit'] = np.where(\n",
    "        pd.isna(df['f_area']) & pd.notna(df['area']),\n",
    "        df['area'].str.extract(r'([a-zA-Z\\-]+)$')[0],\n",
    "        None\n",
    "    )\n",
    "    \n",
    "    df['dupli_price'] = df.apply(\n",
    "        lambda row: row['price'] * (10**7) if pd.isna(row['f_area']) and pd.notna(row['area'])\n",
    "        else None,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    df['dupli_costpersqft'] = np.round(df['dupli_price'].astype('float') / df['dupli_f_area'].astype('float'), 2)\n",
    "    \n",
    "    # Update final columns if missing\n",
    "    def update_values(df, update_cols, using_cols):\n",
    "        for update_col, using_col in zip(update_cols, using_cols):\n",
    "            df[update_col] = np.where(\n",
    "                pd.isna(df['f_area']) & pd.notna(df['area']),\n",
    "                df[using_col],\n",
    "                df[update_col]\n",
    "            )\n",
    "        return df\n",
    "    \n",
    "    # Define columns to update and corresponding columns to use\n",
    "    columns_to_update = ['f_costpersqft', 'f_area_unit', 'f_area']\n",
    "    using_columns = ['dupli_costpersqft', 'dupli_f_area_unit', 'dupli_f_area']\n",
    "    \n",
    "    # Update the DataFrame\n",
    "    df = update_values(df, columns_to_update, using_columns)\n",
    "    \n",
    "    # Drop intermediate columns\n",
    "    cols_to_drop = [\n",
    "        'many_carpet area', 'leftmany_carpet area', 'leftmany_super built-up area', 'many_super built-up area', 'area',\n",
    "        'area_work', 'carpet_area', 'cost_per_sqft', 'area_unit', 'initial_unit',\n",
    "        'super_build_area_work', 'super_build_up_area', 'super_build_up_cost_per_sqft', 'super_built_up_area_unit',\n",
    "        'dupli_f_area', 'dupli_f_area_unit', 'dupli_price', 'dupli_costpersqft', 'f_area_unit'\n",
    "    ]\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "    df = df.rename(columns={'f_area':'area','f_costpersqft':'costpersqft'})\n",
    "\n",
    "    df['area'] = df['area'].astype('float64')\n",
    "\n",
    "    #After analyzing, found some errors in the area column; hence, dropped the rows with the below id's\n",
    "    df = df[~df['id'].isin([\n",
    "        'cardid13695470', 'cardid72545677', 'cardid71119645',\n",
    "        'cardid46503375', 'cardid48667071', 'cardid72200975',\n",
    "        'cardid70294971', 'cardid70608749', 'cardid72754063',\n",
    "        'cardid72078141', 'cardid71460761', 'cardid45089373',\n",
    "        'cardid71419541', 'cardid72848693', 'cardid73238137'\n",
    "    ])]\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #total_floor and flat_on_floor\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['floor_work_1'] = df['many_floor'].combine_first(df['leftmany_floor'])\n",
    "\n",
    "    df['floor_work_1'] = df['floor_work_1'].astype('str') \n",
    "\n",
    "    df['flat_on_floor'] = df['floor_work_1'].apply(\n",
    "        lambda x: x.split('(')[0].strip() if '(' in str(x) else None\n",
    "    )\n",
    "\n",
    "    df['total_floor'] = df['floor_work_1'].apply(\n",
    "        lambda x: x.split('(')[1].strip() if '(' in str(x) else None\n",
    "    )\n",
    "\n",
    "    df['total_floor'] = df['total_floor'].str.extract(r'(\\d+)').astype(float)\n",
    "    \n",
    "    df['flat_on_floor'] = df['flat_on_floor'].replace({'lower basement': -1, 'upper basement': -2,'ground':0})\n",
    "\n",
    "    df['total_floor'] = np.where(\n",
    "        pd.isna(df['total_floor']) & pd.notna(df['md_floors allowed for construction']),\n",
    "        df['md_floors allowed for construction'],\n",
    "        df['total_floor']\n",
    "    )\n",
    "\n",
    "    df['flat_on_floor'] = df['flat_on_floor'].astype('float64')\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #lift\n",
    "    check_more_than_one_value_in_column(df, ['many_lifts', 'md_lift', 'leftmany_lifts', 'many_lift','leftmany_lift'], 'multi_lift_filled','lift') \n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #balcony\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['balcony'] = (\n",
    "        df['bb_balcony']\n",
    "        .combine_first(df['leftbb_balcony'])\n",
    "        .combine_first(df['bb_balconies'])\n",
    "        .combine_first(df['leftbb_balconies'])\n",
    "    )\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #longitude and lattitude\n",
    "    df['lattitude'] = df['geo'].str.split(',').str[1].str.split(':').str[1].str.strip(\" '\\\"\").astype('float')\n",
    "    df['longitude'] = df['geo'].str.split(',').str[2].str.split(':').str[1].str.strip(\" '\\\"}\").astype('float')\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #project_in_acres\n",
    "    # Conversion function for different units to acres\n",
    "    def convert_to_acres(value):\n",
    "        if isinstance(value, str):  # Check if the value is a string\n",
    "            if 'acre' in value:\n",
    "                acres = float(value.replace('acre', '').strip())\n",
    "                return round(acres, 4)  \n",
    "            elif 'sq-m' in value:\n",
    "                sqm = float(value.replace('sq-m', '').strip())\n",
    "                return round(sqm * 0.000247105, 4)  \n",
    "            elif 'sq-ft' in value:\n",
    "                sqft = float(value.replace('sq-ft', '').strip())\n",
    "                return round(sqft * 0.0000229568, 4)  \n",
    "            elif 'hectare' in value:\n",
    "                hectares = float(value.replace('hectare', '').strip())\n",
    "                return round(hectares * 2.47105, 4)  \n",
    "            elif 'sq-yrd' in value:\n",
    "                sq_yrd = float(value.replace('sq-yrd', '').strip())\n",
    "                return round(sq_yrd * 0.000836127, 4)  \n",
    "        elif isinstance(value, (int, float)):  # If value is numeric\n",
    "            return round(value * 0.0000229568, 4)  \n",
    "        return np.nan\n",
    "    \n",
    "    # Apply the conversion to the column\n",
    "    df['project_in_acres'] = df['aboutpjt_project size'].apply(lambda x: convert_to_acres(x))\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    #categorical column\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #builder\n",
    "    df = combine_first_valid(\n",
    "        df,\n",
    "        source_cols=['many_developer','leftmany_developer','ap_buildr'],\n",
    "        new_col_name='builder'\n",
    "    )\n",
    "\n",
    "    def standardize_property_name(name):\n",
    "        \"\"\"\n",
    "        Standardize property names to a single consistent name.\n",
    "        \"\"\"\n",
    "        # Define a mapping of possible variations to standardized names\n",
    "        mapping = {\n",
    "            \"a&o realty / a and o realty / a & o realty ltd.\": \"a&o realty\",\n",
    "            \"adhiraj constructions / adhiraj constructions pvt. ltd.\": \"adhiraj constructions\",\n",
    "            \"arihant superstructures ltd / arihant superstructures ltd.\": \"arihant superstructures ltd\",\n",
    "            \"bharat infrastructure & engineering pvt. ltd. / bharat infrastructure and engineering\": \"bharat infrastructure & engineering\",\n",
    "            \"bhoomi group / bhoomi / bhoomi properties\": \"bhoomi group\",\n",
    "            \"choice group of companies / choice group\": \"choice group\",\n",
    "            \"darshan properties / darshan properties group\": \"darshan properties\",\n",
    "            \"dev land housing / dev land housing ltd.\": \"dev land housing\",\n",
    "            \"ecohomes / eco homes\": \"ecohomes\",\n",
    "            \"gundecha developers / gundecha / gundecha developing milestone /gundecha group\": \"gundecha group\",\n",
    "            \"hiranandani communities / hiranandani constructions / hiranandani developers / hiranandani group / house of hiranandani\": \"hiranandani group\",\n",
    "            \"k raheja realty/ k. raheja realty\": \"k raheja realty\",\n",
    "            \"krishna enterprise / krishna enterprises\": \"krishna enterprise\",\n",
    "            \"l & t realty / l&t realty\": \"l&t realty\",\n",
    "            \"lodha / lodha group\": \"lodha group\",\n",
    "            \"lok housing group / lok group\": \"lok housing group\",\n",
    "            \"lokhandwala builders / lokhandwala constructions / lokhandwala construction industries pvt. ltd. / lokhandwala group\": \"lokhandwala group\",\n",
    "            \"lokhandwala infrastructure\": \"lokhandwala infrastructure\",\n",
    "            \"lotus logistic and developers / lotus logistics & developer pvt ltd\": \"lotus logistics\",\n",
    "            \"neelam realtors / neelam realtors pvt. ltd.\": \"neelam realtors\",\n",
    "            \"neelsidhi group / neelsidhi\": \"neelsidhi group\",\n",
    "            \"nirmal lifestyle / nirmal life style\": \"nirmal lifestyle\",\n",
    "            \"omkar realtors and developers pvt. ltd. / omkar realtors\": \"omkar realtors\",\n",
    "            \"parinee developers / parinee group\": \"parinee group\",\n",
    "            \"platinum group / platinum group builders / platinum constructions\": \"platinum group\",\n",
    "            \"prescon group / prescon\": \"prescon group\",\n",
    "            \"puraniks builders / puranik builders ltd. / puranik group\": \"puraniks group\",\n",
    "            \"r k builders / r k builders and developers\": \"r k builders\",\n",
    "            \"qualcon properties llp / qualcon\": \"qualcon\",\n",
    "            \"raheja universal (pvt.) ltd. / raheja universal pvt. ltd.\": \"raheja universal\",\n",
    "            \"raheja developers / raheja developers ltd.\": \"raheja developers\",\n",
    "            \"raj realty group / raj realty\": \"raj realty group\",\n",
    "            \"rashmi housing pvt. ltd. / rashmi housing\": \"rashmi housing\",\n",
    "            \"ravi group of builders and developers / ravi group\": \"ravi group\",\n",
    "            \"rna / rna ng builders / rna corp / rna group\": \"rna group\",\n",
    "            \"rohan lifescapes / rohan lifescapes ltd.\": \"rohan lifescapes\",\n",
    "            \"romell group / romell real estate pvt. ltd.\": \"romell group\",\n",
    "            \"rustomjee / rustomjee developers\": \"rustomjee\",\n",
    "            \"sahajanand developers / sahajanand infrastructure pvt. ltd.\": \"sahajanand developers\",\n",
    "            \"sainath developers / sainath group\": \"sainath developers\",\n",
    "            \"sapphire group and builder / sapphire group\": \"sapphire group\",\n",
    "            \"saptashree builders & developers / sapta shree builders & developers\": \"saptashree\",\n",
    "            \"shapoorji pallonji real estate / shapoorji pallonji group\": \"shapoorji pallonji group\",\n",
    "            \"sheth creators / sheth creators pvt. ltd.\": \"sheth creators\",\n",
    "            \"shree ostwal builders ltd. / shree ostwal builders and developers\": \"shree ostwal builders\",\n",
    "            \"shreedham builders and developers / shreedham group\": \"shreedham group\",\n",
    "            \"shreeji construction / shreeji group / shreeji group builder and developer\": \"shreeji group\",\n",
    "            \"smgk associates / smgk group\": \"smgk group\",\n",
    "            \"space india / space india builders & developers\": \"space india\",\n",
    "            \"spenta builders / spenta corp. pvt. ltd.\": \"spenta\",\n",
    "            \"sugee realty & developers (india) pvt. ltd. / sugee group\": \"sugee group\",\n",
    "            \"swastik realtors / swastik group builders & developers\": \"swastik\",\n",
    "            \"tharwani realty / tharwani group\": \"tharwani group\",\n",
    "            \"titanium group / titanium builders and developers\": \"titanium group\",\n",
    "            \"today global homes / today global builders & developers\": \"today global\",\n",
    "            \"transcon developers / transcon group\": \"transcon group\",\n",
    "            \"tridhaatu realty / tridhaatu realty & infra pvt. ltd.\": \"tridhaatu realty\",\n",
    "            \"vaibhavlaxmi builders & developers / vaibhavlaxmi builders and developers / vaibhav laxmi developers\": \"vaibhavlaxmi builders\",\n",
    "            \"vbhc value homes pvt. ltd. / vbhc\": \"vbhc\",\n",
    "            \"vihang infrastructure pvt ltd / vihang group\": \"vihang group\",\n",
    "            \"vinay unique developers / vinay unique group\": \"vinay unique group\"\n",
    "        }\n",
    "    \n",
    "        # Handle null or missing values\n",
    "        if not isinstance(name, str):\n",
    "            return name\n",
    "    \n",
    "        # Normalize input name (e.g., lowercase, strip whitespace)\n",
    "        normalized_name = name.strip().lower()\n",
    "    \n",
    "        # Standardize using the mapping\n",
    "        for key, value in mapping.items():\n",
    "            variations = key.split(\" / \")\n",
    "            if normalized_name in variations:\n",
    "                return value\n",
    "    \n",
    "        # Return the original name if no match is found\n",
    "        return name\n",
    "    \n",
    "    # Apply the function to the 'builder' column of a DataFrame\n",
    "    df['builder'] = df['builder'].apply(standardize_property_name)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #project_name\n",
    "    df = combine_first_valid(\n",
    "        df,\n",
    "        source_cols=['ap_pjt_name', 'many_project', 'leftmany_project'],\n",
    "        new_col_name='project_name'\n",
    "    )\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #furnish\n",
    "    df = combine_first_valid(\n",
    "        df,\n",
    "        source_cols=['md_furnishing','many_furnished status','leftmany_furnished status'],\n",
    "        new_col_name='furnish'\n",
    "    )\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #city\n",
    "    df = df.rename(columns={'address':'wholeaddress'})\n",
    "\n",
    "    df['addressregion'] = df['wholeaddress'].apply(\n",
    "        lambda x: ast.literal_eval(x).get('addressregion') if isinstance(x, str) else x.get('addressregion')\n",
    "    )\n",
    "\n",
    "    \n",
    "    #rename\n",
    "    df = df.rename(columns={'md_address':'address'})\n",
    "\n",
    "    df = df.rename(columns = {'addressregion':'city'})\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #location\n",
    "    # Convert string representation of dictionaries to actual dictionaries\n",
    "    df[\"wholeaddress\"] = df[\"wholeaddress\"].apply(ast.literal_eval)\n",
    "    \n",
    "    # Extract 'addresslocality' into a new column\n",
    "    df[\"location\"] = df[\"wholeaddress\"].apply(lambda x: x.get(\"addresslocality\", \"\"))\n",
    "    \n",
    "    #make rd as road in address column\n",
    "    df['address'] = df['address'].astype(str).str.replace(r'\\brd\\b', 'road', regex=True)\n",
    "    \n",
    "    #if below values match found in address column,then update location with the matched value\n",
    "    \n",
    "    lst = [\n",
    "        \"mira road east\", \"mira road west\", \"mira rd east\", \"mira rd west\",\n",
    "        \"vile parle east\", \"vile parle west\", \"lower parel west\", \"lower parel east\",\n",
    "        \"new panvel east\", \"new panvel west\", \"grand road east\", \"grand road west\",\n",
    "        \"charni road east\", \"charni road west\", \"grand rd east\", \"grand rd west\",\n",
    "        \"charni rd east\", \"charni rd west\", \"kanjur marg east\", \"kanjur marg west\",\n",
    "        \"mira bhayandar east\", \"mira bhayandar west\", \"marine lines east\", \"marine lines west\",\n",
    "        \"ram mandir west\", \"ram mandir east\", \"vasai road west\", \"vasai road east\",\n",
    "        \"matunga road west\", \"matunga road east\", \"vasai rd west\", \"vasai rd east\",\n",
    "        \"matunga rd west\", \"matunga rd east\", \"rajendra nagar west\", \"rajendra nagar east\",\n",
    "        \"tilak nagar west\", \"tilak nagar east\", \"diva station east\", \"diva station west\",\n",
    "        \"ville parla west\", \"ville parla east\", \"lower pare west\", \"lower pare east\",\n",
    "        \"mumbai central east\", \"mumbai central west\"\n",
    "    ]\n",
    "    # Step 1: Filter NaN rows\n",
    "    df_nan1 = df[df['location'].isna()].copy()\n",
    "    \n",
    "    # Step 2 & 3: Match with lst and update location\n",
    "    for index, row in df_nan1.iterrows():\n",
    "        for loc in lst:\n",
    "            if loc in row['address'].lower():  # Case insensitive match\n",
    "                df.at[index, 'location'] = loc\n",
    "                break  # Stop at first match\n",
    "\n",
    "    # Function to extract \"<name> east\" or \"<name> west\" from 'address'\n",
    "    def extract_location(address):\n",
    "        # Use regex to find a word followed by 'east' or 'west'\n",
    "        match = re.search(r'(\\w+)\\s+(east|west)', address, re.IGNORECASE)\n",
    "        if match:\n",
    "            return f\"{match.group(1)} {match.group(2)}\"\n",
    "        return np.nan  # If no match, return NaN\n",
    "    \n",
    "    # Filter the rows where 'location' is NaN\n",
    "    df_nan2 = df[df['location'].isna()]\n",
    "    \n",
    "    # Apply the extract_location function only to the 'address' column in the filtered rows\n",
    "    df.loc[df_nan2.index, 'location'] = df_nan2['address'].apply(extract_location)\n",
    "    \n",
    "    mapping = {\"near naupada police station, thane, maharashtra\" : \"thane west\",\n",
    "            \"new suyash chs naupada, thane, maharashtra\" : \"thane west\",\n",
    "            \"marine lines, mumbai, maharashtra\" : \"marine lines\",\n",
    "            \"kalher, thane, maharashtra\" : \"bhiwandi\",\n",
    "            \"kanikiya beverly park mira road, mumbai, maharashtra\" : \"mira road east\",\n",
    "            \"204, 2nd flr, ramraj bldg, nr. ram mandir, rajanpada - sector-27, navi mumbai, maharashtra\" : \"sector 27 rajanpada\",\n",
    "            \"202 dhrmasetu plot no 2225 sec 19 koperkhairane, navi mumbai, maharashtra\" : \"sector 19 koperkhairane\",\n",
    "            \"kashimira near whestran express hyway, mumbai, maharashtra\" : \"mira road east\",\n",
    "            \"near burhani college mazgaon mumbai 10, mumbai, maharashtra\" : \"mazgaon\",\n",
    "            \"ulwe sector 21, navi mumbai, maharashtra\" : \"sector 21 ulwe\",\n",
    "            \"lakeshore greens by lodha, thane, maharashtra\" : \"dombivli west\",\n",
    "            \"santa cruz, mumbai, maharashtra\" : \"santacruz\",\n",
    "            \"kopar khairane, navi mumbai, maharashtra\" : \"koparkhairane\",\n",
    "            \"1801, 18th floor, chunam lane, lamington road, grantroad e, mumbai 400007, mumbai, maharashtra\" : \"grant road east\",\n",
    "            \"charkop village near dingeshwar talao and jalaram temple, mumbai, maharashtra\" : \"kandivali west\",\n",
    "            \"sarfaraz iqbal heights, ymca road 3, near maratha mandir, mumbai central, mumbai, maharashtra\" : \"mumbai central\",\n",
    "            \"panchseel heights, mahavir nagar, mumbai, maharashtra\" : \"kandivali west\",\n",
    "            \"sector 5 pushpak nagar, navi mumbai, maharashtra\" : \"sector 5 pushpak nagar\",\n",
    "            \"poonam park view, global city, virar, thane, maharashtra\" : \"virar west\",\n",
    "            \"om ekdant soc, sec-19, koperkharine, near jummy tower, navi mumbai, maharashtra\" : \"sector 19 koperkharine\",\n",
    "            \"sai vrindhavan koparkhairne., navi mumbai, maharashtra\" : \"koparkhairne\",\n",
    "            \"owale, ghodbunder road, thane, maharashtra\" : \"thane west\",\n",
    "            \"sector 21 ulwe, navi mumbai, maharashtra\" : \"sector 21 ulwe\",\n",
    "            \"dombivli, mumbai, maharashtra\" : \"dombivli\",\n",
    "            \"amber enclave - 3rd floor thakurli e, mumbai, maharashtra\" : \"thakurli east\",\n",
    "            \"anath sai apartment, thane, maharashtra\" : \"thane west\",\n",
    "            \"willingdon heights 32nd flr near tardeo rto tulsiwadi, mumbai, maharashtra\" : \"tardeo\",\n",
    "            \"12th floor c2 wing treetops lodha upper thane mankoli bhiwandi thane maharashtra 421302, mumbai, maharashtra\" : \"bhiwandi\",\n",
    "            \"chincholi phatak, mumbai, maharashtra\" : \"malad west\",\n",
    "            \"kanakiya, mumbai, maharashtra\" : \"kandivali east\",\n",
    "            \"puranik hometown kasarvadavli, mumbai, maharashtra\" : \"thane west\",\n",
    "            \"boraivali w 401, mumbai, maharashtra\" : \"borivali west\",\n",
    "            \"prabhadevi, mumbai, maharashtra\" : \"prabhadevi\",\n",
    "            \"green road, thane, maharashtra\" : \"thane west\",\n",
    "            \"lagoona, thane, maharashtra\" : \"thane west\",\n",
    "            \"kasarvadavli, thane, maharashtra\" : \"thane west\",\n",
    "            \"kasarvadavli, thane, maharashtra\" : \"thane west\",\n",
    "            \"dr annie besant road, worli, mumbai, maharashtra 400018, india, mumbai, maharashtra\" : \"worli\",\n",
    "            \"gorai 2, mumbai, maharashtra\" : \"gorai\",\n",
    "            \"lodha casa lakeshore green khoni dombivli, nilje gaon, maharashtra 421204, india, thane, maharashtra\" : \"dombivli east\",\n",
    "            \"diamind garden chembur, mumbai, maharashtra\" : \"chembur\",\n",
    "            \"sector 17 kamothe, navi mumbai, maharashtra\" : \"kamothe\",\n",
    "            \"highland complex, mumbai, maharashtra\" : \"kandivali east\",\n",
    "            \"jerbai wadia road, near tata hospital, parel, mumbai, maharashtra\" : \"parel\",\n",
    "            \"gokhale road, naupada thane, thane, maharashtra\" : \"naupada\",\n",
    "            \"taloja phase 2, navi mumbai, maharashtra\" : \"taloja\",\n",
    "            \"ghansoli sector 11, navi mumbai, maharashtra\" : \"ghansoli\",\n",
    "            \"ramnagar, thane, maharashtra\" : \"thane west\",\n",
    "            \"ram maruti, thane, maharashtra\" : \"thane west\",\n",
    "            \"marine lines, mumbai, maharashtra\" : \"marine lines\",\n",
    "            \"sector 12 vashi., navi mumbai, maharashtra\" : \"sector 12 vashi\",\n",
    "            \"just opposite of mansarovar railway station, navi mumbai, maharashtra\" : \"mansarovar\",\n",
    "            \"bhaskar colony, thane, maharashtra\" : \"thane west\",\n",
    "            \"taloja phase 2, navi mumbai, maharashtra\" : \"taloja\",\n",
    "            \"charkop sector 3charkop gaon, mumbai, maharashtra\" : \"kandivali west\",\n",
    "            \"157, pantnagar, 1st building naidu colony, mumbai, maharashtra\" : \"ghatkopar east\",\n",
    "            \"godrej chandivali, mumbai, maharashtra\" : \"chandivali\",\n",
    "            \"kalwa, thane, thane, maharashtra\" : \"kalwa\",\n",
    "            \"ghansoli, navi mumbai, maharashtra\" : \"ghansoli\",\n",
    "            \"suncity corner seawoodnerul, navi mumbai, maharashtra\" : \"nerul\",\n",
    "            \"lagoona, thane, maharashtra\" : \"dombivli east\",\n",
    "            \"satyam apartment, sector 19, kharghar, navi mumbai, maharashtra\" : \"kharghar\",\n",
    "            \"tilak nagar chembur, mumbai 400089., mumbai, maharashtra\" : \"chembur\",\n",
    "            \"401, sai aakash co op housing society, plot no.23, sector 18, ulwe, navi mumbai, maharashtra\" : \"sector 18 ulwe\",\n",
    "            \"palava casa bella gold, mumbai, maharashtra\" : \"palava\",\n",
    "            \"near vitthal mandir kharigaon kalwa, thane, maharashtra\" : \"kalwa\",\n",
    "            \"kharghar, navi mumbai, maharashtra\" : \"kharghar\",\n",
    "            \"neral karjat, mumbai, maharashtra\" : \"neral\",\n",
    "            \"pahhal avenue, mumbai, maharashtra\" : \"goregaon west\",\n",
    "            \"157, naidu colony, pantnagar, mumbai, maharashtra\" : \"ghatkopar east\",\n",
    "            \"mangalmurthy complex, temghar, thane, maharashtra\" : \"bhiwandi\",\n",
    "            \"plot no b1b, sector 9, airoli navimumbai, mumbai, maharashtra\" : \"sector 9 airoli\",\n",
    "            \"chikhloli jambul phata, thane, maharashtra\" : \"chikhloli\",\n",
    "            \"bapu nagar apartment., thane, maharashtra\" : \"bapu nagar\",\n",
    "            \"crown taloja by lodha, taloja bypass phata, antarli, maharashtra 421204, mumbai, maharashtra\" : \"taloja\",\n",
    "            \"morya garden residency vichumbe, navi mumbai, maharashtra\" : \"new panvel east\",\n",
    "            \"sec-19, navi mumbai, maharashtra\" : \"sector 19 navi mumbai\",\n",
    "            \"siddhivinayak appartment airoli diva koliwada near airoli mulund bridge diva goan gavthan, navi mumbai, maharashtra\" : \"airoli\",  \n",
    "            \"kalher, thane, maharashtra\" : \"kalher\",  \n",
    "            \"vinay nagar, mira road, mumbai, maharashtra\" : \"mira road east\",\n",
    "            \"shree siddhivinayak tower vartaknagar, thane, maharashtra\" : \"vartaknagar\",\n",
    "            \"kasarwadvali godbandar road thane, thane, maharashtra\" : \"kasarwadvali\",  \n",
    "            \"panvel matheran road opp balaji symphony sukapur, navi mumbai, maharashtra\" : \"panvel\",\n",
    "            \"sector 19, shahbaz gaon, cbd belapur, navi mumbai, navi mumbai, maharashtra\" : \"cbd belapur\",\n",
    "            \"gamdevi grant road, mumbai, maharashtra\" : \"gamdevi\",\n",
    "            \"dongri sandhurst road, mumbai, maharashtra\" : \"dongri\",\n",
    "            \"casa rio arebiana, thane, maharashtra\" : \"thane\",\n",
    "            \"lalani dreams residency, village dahivali turfe nid, taluka karjat, mumbai, maharashtra\" : \"karjat\",\n",
    "            \"lodha crown akbar camp road kolshet mumbai maharashtra, mumbai, maharashtra\" : \"kolshet\",  \n",
    "            \"202 sai shruti residency plot c 30 sector 4 khanda colony new panvel 410206, navi mumbai, maharashtra\" : \"new panvel\",  \n",
    "            \"casa milano 12th floor - lodha palava phase 2 dombivali kalyan, navi mumbai, maharashtra\" : \"dombivli\",  \n",
    "            \"203, sunrise glory shilphata near daighar police station, navi mumbai, maharashtra\" : \"shilphata\", \n",
    "            \"dronagiri navi mumbai., mumbai, maharashtra\" : \"dronagiri\",  \n",
    "            \"muthaval, thane, maharashtra\" : \"muthaval\",  \n",
    "            \"sector 5 koperkhairne navi mumbai, navi mumbai, maharashtra\" : \"koperkhairne\",  \n",
    "            \"304, audumber chaya chsl, patilwadi, savarkar nagar, behind thakur college, thane, maharashtra\" : \"thane west\",\n",
    "            \"old panvel near savarkar chowk., navi mumbai, maharashtra\" : \"old panvel\",  \n",
    "            \"opposite j p international school haranwadi naka, mahim road, palghar, palghar, maharashtra\" : \"palghar\",\n",
    "            \"tower 13 2003 runwal gardens dombivali, thane, maharashtra\" : \"dombivli\",\n",
    "            \"village boisar, tal palghar, dist. thane, palghar, maharashtra\" : \"boisar\",  \n",
    "            \"century bazar near chroma showroom, mumbai, maharashtra\" : \"century bazar\",  \n",
    "            \"d/305., palghar, maharashtra\" : \"palghar\",  \n",
    "            \"e 2 303 gaurav citymira road area, mumbai, maharashtra\" : \"mira road east\",\n",
    "            \"umiya darshan chs, nerul sec 50 new, navi mumbaiseawoods, navi mumbai, maharashtra\" : \"seawoods\",  \n",
    "            \"rambhau mhalgi marg, besides shrushti residency, khambalpada, thakurli e, dombivli e, thane, maharashtra\" : \"thakurli east\",\n",
    "            \"ramabai paradise opp garden city tawor mira road thane, mumbai, maharashtra\" : \"mira road\",  \n",
    "            \"siddhivinayak florentia garden citymira bhayandar, mumbai, maharashtra\" : \"mira bhayandar\",  \n",
    "            \"bonkode sector 12, navi mumbai, maharashtra\" : \"sector 12 bonkode\",  \n",
    "            \"vasant villa, padmavati devi marg, iit market, powai, mumbai 400076, mumbai, maharashtra\" : \"powai\",  \n",
    "            \"novapark co opp housing society ltd flat no 303 plot no 68., navi mumbai, maharashtra\" : \"navi mumbai\",\n",
    "            \"mira road area, mumbai, maharashtra\" : \"mira road\",  \n",
    "            \"near divya heights in sector 26 navi mumbai, navi mumbai, maharashtra\" : \"sector 26 navi mumbai\",\n",
    "            \"ganesh nagar, near boisar railway starion, palghar, maharashtra\" : \"boisar\",  \n",
    "            \"c-001 nand dham building kashimira mira road, mumbai, maharashtra\" : \"mira road east\",\n",
    "            \"om sankalp chs, kopar road, thane 421202, thane, maharashtra\" : \"dombivli west\",\n",
    "            \"svarna kojagiri, mumbai, maharashtra\" : \"goregaon east\",\n",
    "            \"unique aurum, poonam garden, thane, maharashtra\" : \"mira road east\",\n",
    "            \"neelkanth darshan society b-203125a near hotel panvel palaceold panvel, mumbai, maharashtra\" : \"old panvel\",\n",
    "            \"mira road kanakia, thane, maharashtra\" : \"mira road east\",\n",
    "            \"panvel, navi mumbai, navi mumbai, maharashtra\" : \"navi mumbai\",\n",
    "            \"chitalsar manpada, thane, maharashtra\" : \"manpada\",  \n",
    "            \"near raj kamal studio, parel, mumbai, maharashtra\" : \"parel\",  \n",
    "            \"nilje station road, nilje, thane, maharashtra\" : \"nilje\", \n",
    "            \"flat no-604, plot no-4, sector 14, taloja, navi mumbai, maharashtra\" : \"taloja\",  \n",
    "            \"jethe tower, 701, ambawadi, opp. ambawadi bus stop, borivali e. mumbai-400068, mumbai, maharashtra\" : \"borivali east\",  \n",
    "            \"lodha crown viva, flat 1006, 10th flr tower 5, majiwada, thane, mumbai, maharashtra\" : \"majiwada\",  \n",
    "            \"sunbeam heritage hsg soc, sector 4c, khanda colony asudgoan panvel, navi mumbai, maharashtra\" : \"panvel\",\n",
    "            \"lodha upper thane, treetops, thane, maharashtra\" : \"upper thane\",  \n",
    "            \"aanandi park a101 behind ganapati mandir durgesh park kalher bhiwandi, thane, maharashtra\" : \"kalher\",  \n",
    "            \"a-9/201 tejaswi apt, near st. thomas church, sai baba nagar, mira road., mumbai, maharashtra\" : \"mira road east\",\n",
    "            \"sector 11, next to miraj cinema, navi mumbai, maharashtra\" : \"sector 11\",\n",
    "            \"aster, regency anantham, dombivli, mumbai, maharashtra\" : \"dombivli\",  \n",
    "            \"chand nagar, near baba medical, thane, maharashtra\" : \"thane\", \n",
    "            \"thane majiwada lodha complex opp-water tank, thane, maharashtra\" : \"majiwada\",  \n",
    "            \"near kalidas natyamamdir, mumbai, maharashtra\" : \"mulund west\",\n",
    "            \"badlapur, thane, maharashtra\" : \"badlapur\",  \n",
    "            \"near mittal club, palghar, maharashtra\" : \"palghar\",  \n",
    "            \"shree krupa apt flat no 102 plot144145 sector10 new panvel navi mumbai, navi mumbai, maharashtra\" : \"new panvel\",  \n",
    "            \"sector 20, cbd belapur opp bank of india  park, adjacent to hansraj building, navi mumbai, maharashtra\" : \"sector 20 cbd belapur\",  \n",
    "            \"brahmand patlipada link road, opp tulsi hotel, thane, maharashtra\" : \"thane\",  \n",
    "            \"gurukiran socity airoli sector 30 gothavali, navi mumbai, maharashtra\" : \"sector 30 gothavali\"}\n",
    "    \n",
    "    # Fill \"location\" based on \"address\" matching mapping dictionary\n",
    "    df.loc[df[\"location\"].isna(), \"location\"] = df[\"address\"].map(mapping)\n",
    "\n",
    "    # Mapping dictionary\n",
    "    replace_dict = {\n",
    "        \"bhayander\": \"bhayandar\",\n",
    "        \"century Bazar\": \"century bazaar\",\n",
    "        \"dombivali\": \"dombivli\",\n",
    "        \"kasarwadvali\": \"kasarvadavali\",\n",
    "        \"koparkhairane\": \"kopar khairane\",\n",
    "        \"koparkhairne\": \"kopar khairane\",\n",
    "        \"koperkhairne\": \"kopar khairane\",\n",
    "        \"koperkhairane\": \"kopar khairane\",\n",
    "        \"koperkharine\": \"kopar khairane\",\n",
    "        \"mulund goregaon link road\": \"goregaon mulund link road\",\n",
    "        \"naigoan\": \"naigaon\",\n",
    "        \"nalasopara\": \"nala sopara\",\n",
    "        \"nallasopara\": \"nala sopara\",\n",
    "        \"palaspe phata\": \"palaspa\",\n",
    "        \"palava\": \"palava city\",\n",
    "        \"shil phata\": \"shilphata\",\n",
    "        \"vartaknagar\": \"vartak nagar\",\n",
    "        \"vileparle\": \"vile parle\",\n",
    "        \"4 east\": \"ulhasnagar\",\n",
    "        \"402borivali west\": \"borivali west\",\n",
    "        \"adai\": \"adai navi mumbai\"  # Careful with this if \"adai\" alone is meant to be corrected\n",
    "    }\n",
    "    \n",
    "    # Function to apply mapping\n",
    "    def correct_location(location):\n",
    "        for wrong, correct in replace_dict.items():\n",
    "            if pd.notnull(location) and wrong.lower() in location.lower():\n",
    "                # Replace wrong word with correct one (case-insensitive)\n",
    "                location = location.lower().replace(wrong.lower(), correct.lower())\n",
    "        return location\n",
    "    \n",
    "    # Apply correction function\n",
    "    df['location'] = df['location'].apply(correct_location)\n",
    "\n",
    "    location_mapping = {\n",
    "        \"mulund airoli road\": \"navi mumbai\",\n",
    "        \"taloja bypass road\": \"navi mumbai\",\n",
    "        \"panvel\": \"navi mumbai\",\n",
    "        \"sector 9 airoli\": \"navi mumbai\",\n",
    "        \"taloja\": \"navi mumbai\",\n",
    "        \"old panvel\": \"navi mumbai\",\n",
    "        \"naigaon east vasai link road\": \"palghar\",\n",
    "        \"naigaon palghar\": \"palghar\",\n",
    "        \"vasai\": \"palghar\",\n",
    "        \"vasai east\": \"palghar\",\n",
    "        \"vasai road west\": \"palghar\",\n",
    "        \"vasai west\": \"palghar\",\n",
    "        \"virar\": \"palghar\",\n",
    "        \"virar east\": \"palghar\",\n",
    "        \"virar west\": \"palghar\",\n",
    "        \"thane west\": \"thane\",\n",
    "        \"kolshet\": \"thane\",\n",
    "        \"majiwada\": \"thane\",\n",
    "        \"kandivali east\": \"mumbai\",\n",
    "        \"thane belapur road\": \"thane\",\n",
    "        \"mahim\": \"mumbai\",\n",
    "        \"bhayandar\": \"thane\",\n",
    "        \"bhayandar east\": \"thane\",\n",
    "        \"bhayandar west\": \"thane\",\n",
    "        \"bhayandarpada\": \"thane\",\n",
    "        \"mira bhayandar\": \"thane\",\n",
    "        \"mira bhayandar road\": \"thane\",\n",
    "        \"mira road\": \"thane\",\n",
    "        \"mira road area\": \"thane\",\n",
    "        \"mira road east\": \"thane\",\n",
    "        \"nala sopara\": \"palghar\",\n",
    "        \"naigaon east\": \"palghar\",\n",
    "        \"naigaon west\": \"palghar\",\n",
    "        \"nala sopara east\": \"palghar\",\n",
    "        \"nala sopara west\": \"palghar\",\n",
    "        \"kharghar\": \"navi mumbai\"\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Update city based on location presence\n",
    "    for key, value in location_mapping.items():\n",
    "        df.loc[df[\"location\"].str.contains(key, case=False, na=False), \"city\"] = value\n",
    "\n",
    "    df['location'] = df['location'].replace('', np.nan)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # property_type : New property, Resale, Rent, Other\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['property_type'] = df[\"many_transaction type\"].combine_first(df[\"leftmany_transaction type\"])\n",
    "\n",
    "    df = df[~df['property_type'].isin(['other', 'rent'])]\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # ownership\n",
    "    df = df.rename(columns={'md_type of ownership': 'ownership'})\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #status\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['status'] = df['many_status'].combine_first(df['leftmany_status'])\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #construction\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['construction_1'] = df['many_age of construction'].combine_first(df['leftmany_age of construction'])\n",
    "\n",
    "    df = df.rename(columns={'md_age of construction': 'construction'})\n",
    "\n",
    "    df['construction'] = df.apply(\n",
    "        lambda row: 'under construction' if row['status'] == 'under construction' else row['construction'], axis=1\n",
    "    )\n",
    "\n",
    "    df['status'] = df.apply(\n",
    "        lambda row: 'under construction' if row['construction'] == 'under construction' else row['status'], axis=1\n",
    "    )\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #extra rooms \n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['balcony1'] = df['leftmany_additional rooms'].combine_first(df['many_additional rooms'])\n",
    "    \n",
    "    df['extra_room'] = df['balcony1'].str.split(' ').str[1].str.strip()\n",
    "    \n",
    "    result = df['extra_room'].apply(\n",
    "        lambda x: any(str(x) in str(room) for room in df['md_additional rooms']) if pd.notnull(x) else False\n",
    "    )\n",
    "    \n",
    "    #sort value alphabetically \n",
    "    df['extra_rooms'] = df['md_additional rooms'].apply(\n",
    "        lambda x: ', '.join(sorted(x.split(', '))) if pd.notna(x) else None\n",
    "    )\n",
    "    \n",
    "    #remove none of these eg:from these 'none of these, store' and keep only store \n",
    "    #but if we have only 'none of these' then we keep that as it is \n",
    "    #also remove room word from all values \n",
    "    \n",
    "    df['extra_rooms'] = df['md_additional rooms'].apply(\n",
    "        lambda x: x if pd.isna(x) or str(x).strip() == 'none of these' else ', '.join(\n",
    "            [item.replace(' room', '') for item in str(x).split(', ') if item != 'none of these']\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Facing\n",
    "    #combine_first Update null elements with value in the same location in other.\n",
    "    df['facing'] = df['leftmany_facing'].combine_first(df['many_facing'])\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #towers and available_units\n",
    "    df = df.rename(columns={'aboutpjt_total units': 'available_units', \n",
    "                        'aboutpjt_total towers': 'towers'})\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #seller\n",
    "    df['seller'] = df['potentialaction'].str.split(',').str[1].str.split(':').str[2].str.strip(\" '\\\"\")\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #price_category\n",
    "    # Define price bins and labels\n",
    "    price_bins = [0, 0.99, 1.99, 2.99, 3.99, 4.99, 5.99, 6.99, 7.99, 8.99, 9.99, 14.99, 20.00, float('inf')]\n",
    "    price_labels = [\n",
    "        \"0.00 - 0.99\", \"1.00 - 1.99\", \"2.00 - 2.99\", \"3.00 - 3.99\", \"4.00 - 4.99\", \n",
    "        \"5.00 - 5.99\", \"6.00 - 6.99\", \"7.00 - 7.99\", \"8.00 - 8.99\", \"9.00 - 9.99\", \n",
    "        \"10.00 - 14.99\", \"15.00 - 20.00\", \"20.00 and above\"\n",
    "    ]\n",
    "    \n",
    "    # Use pd.cut to categorize the prices\n",
    "    df['price_category'] = pd.cut(df['price'], bins=price_bins, labels=price_labels, right=True)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #overlooking\n",
    "    df['overlooking'] = df['md_overlooking'].apply(\n",
    "        lambda x: ', '.join(sorted(map(str.strip, x.split(',')))) if pd.notna(x) else np.nan\n",
    "    )\n",
    "    \n",
    "    # Remove the phrase 'not available' from the 'overlooking' column\n",
    "    df['overlooking'] = df['overlooking'].str.replace(',? *not available', '', regex=True)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #room_type\n",
    "    df['room_type'] = df['name'].apply(lambda x: 'flat' if 'flat' in x else ('apartment' if 'apartment' in x else 'other'))\n",
    "\n",
    "    #drop apartment rows\n",
    "    df = df[df['room_type'] != 'apartment']\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #nearby_location_km\n",
    "\n",
    "    # Reusable function\n",
    "    def combine_columns(df, cols, new_col):\n",
    "        df[new_col] = df[cols].apply(lambda row: ', '.join(filter(pd.notna, row)), axis=1)\n",
    "    \n",
    "    # Education\n",
    "    combine_columns(df, [\n",
    "        'educational institute_1', 'educational institute_2', \n",
    "        'educational institute_3', 'educational institute_4', \n",
    "        'educational institute_5'\n",
    "    ], 'education')\n",
    "    \n",
    "    # Transport\n",
    "    combine_columns(df, [\n",
    "        'transportation hub_1', 'transportation hub_2', \n",
    "        'transportation hub_3', 'transportation hub_4', \n",
    "        'transportation hub_5'\n",
    "    ], 'transport')\n",
    "    \n",
    "    # Shopping Centre\n",
    "    combine_columns(df, [\n",
    "        'shopping centre_1', 'shopping centre_2', \n",
    "        'shopping centre_3', 'shopping centre_4', \n",
    "        'shopping centre_5'\n",
    "    ], 'shopping_centre')\n",
    "    \n",
    "    # Commercial Hub\n",
    "    combine_columns(df, [\n",
    "        'commercial hub_1', 'commercial hub_2', \n",
    "        'commercial hub_3', 'commercial hub_4', \n",
    "        'commercial hub_5'\n",
    "    ], 'commercial_hub')\n",
    "    \n",
    "    # Hospital\n",
    "    combine_columns(df, [\n",
    "        'hospital_1', 'hospital_2', \n",
    "        'hospital_3', 'hospital_4', \n",
    "        'hospital_5'\n",
    "    ], 'hospital')\n",
    "    \n",
    "    # Tourist\n",
    "    combine_columns(df, [\n",
    "        'tourist spot_1', 'tourist spot_2', \n",
    "        'tourist spot_3', 'tourist spot_4'\n",
    "    ], 'tourist')\n",
    "\n",
    "    # Function to extract mean km from text\n",
    "    # Initialize global zero counter\n",
    "    #zero_count = 0\n",
    "    \n",
    "    # Function to extract mean km with zero replacement\n",
    "    def extract_mean_km(text):\n",
    "        #global zero_count\n",
    "        if pd.isna(text):\n",
    "            return np.nan\n",
    "        km_values = [float(x) for x in re.findall(r'([\\d.]+)\\s*km', text)]\n",
    "        if any(km == 0.0 for km in km_values):\n",
    "            #zero_count += 1\n",
    "            km_values = [0.0001 if km == 0.0 else km for km in km_values] #reason for this code given below \n",
    "        return sum(km_values) / len(km_values) if km_values else np.nan\n",
    "    \n",
    "    # Function to extract min km with zero replacement\n",
    "    def extract_min_km(text):\n",
    "        if pd.isna(text):\n",
    "            return np.nan\n",
    "        km_values = [float(x) for x in re.findall(r'([\\d.]+)\\s*km', text)]\n",
    "        km_values = [0.0001 if km == 0.0 else km for km in km_values]\n",
    "        return min(km_values) if km_values else np.nan\n",
    "    \n",
    "    # Apply to column\n",
    "    df['education_mean_km'] = df['education'].apply(extract_mean_km)\n",
    "    df['education_min_km'] = df['education'].apply(extract_min_km)\n",
    "    \n",
    "    # Print your zero count!\n",
    "    #print(f\"\\nRows containing zero km replaced: {zero_count}\") #print no of zero km values in data , \n",
    "                                                                #means something which is in zero km , like hospital in building so it become zero km\n",
    "                                                                #for such data make 0.0001 km just make identify them as there is location of hospital or any other \n",
    "                                                                #if we keep 0 km only then it may means that there is no location for that property \n",
    "                                                                #if any there is hospital location which is inside building or something then it become 0.0 km so this get counut as 1\n",
    "                                                                #in hospital_within_2km\n",
    "    \n",
    "    \n",
    "    # Function to count places within 2 km\n",
    "    #so one row has so many values and from that how many are within 2km that we count here\n",
    "    #eg: [1.0,3.0,1.9,4.8] so here it is 2\n",
    "    def count_within_2km(text):\n",
    "        if pd.isna(text):\n",
    "            return np.nan\n",
    "        km_values = [float(x) for x in re.findall(r'([\\d.]+)\\s*km', text)]\n",
    "        return sum(1 for km in km_values if km <= 2.0)\n",
    "    \n",
    "    # List of combined location columns\n",
    "    location_cols = ['education', 'transport', 'shopping_centre', 'commercial_hub', 'hospital', 'tourist']\n",
    "    \n",
    "    # Apply all 3 functions: mean, min, within_2km\n",
    "    for col in location_cols:\n",
    "        df[col + '_mean_km'] = df[col].apply(extract_mean_km)\n",
    "        df[col + '_min_km'] = df[col].apply(extract_min_km)\n",
    "        df[col + '_within_2km'] = df[col].apply(count_within_2km)\n",
    "    \n",
    "    # Show only mean and min columns\n",
    "    mean_cols = [col + '_mean_km' for col in location_cols]\n",
    "    min_cols = [col + '_min_km' for col in location_cols]\n",
    "    within_2km_cols = [col + '_within_2km' for col in location_cols]\n",
    "    \n",
    "    # Add final 5 summary columns\n",
    "    df['overall_min_mean_km'] = df[mean_cols].min(axis=1)\n",
    "    df['overall_avg_mean_km'] = df[mean_cols].mean(axis=1)\n",
    "    df['overall_min_min_km'] = df[min_cols].min(axis=1)\n",
    "    df['overall_avg_min_km'] = df[min_cols].mean(axis=1)\n",
    "    df['total_within_2km'] = df[within_2km_cols].sum(axis=1) #sum of all within_2km location_cols\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #flooring\n",
    "    df = df.rename(columns={'md_flooring':'flooring'})\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #amenities\n",
    "    # Select columns that start with 'am_' and include 'id'\n",
    "    #am_cols = ['id'] + [col for col in df.columns if col.startswith('am_')]\n",
    "    \n",
    "    # Create a separate DataFrame with those columns\n",
    "    #am_df = df[am_cols].copy()\n",
    "    \n",
    "    # Drop 'am_' columns from the original DataFrame (keep 'id')\n",
    "    #df = df.drop(columns=[col for col in df.columns if col.startswith('am_')])\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #Custom data corrections and row-level cleaning\n",
    "\n",
    "    # List of IDs to remove\n",
    "    ids_to_remove = [\n",
    "        'cardid70421965',  \n",
    "        'cardid71698587',\n",
    "        'cardid41440251',\n",
    "        'cardid70017925',  \n",
    "        'cardid73050463',\n",
    "        'cardid49131617',\n",
    "        'cardid72273473',\n",
    "        'cardid66762427',\n",
    "        'cardid70615879',\n",
    "        'cardid72819785',\n",
    "        'cardid71143703',\n",
    "        'cardid72821117',\n",
    "        'cardid72884955',\n",
    "        'cardid72803713',\n",
    "        'cardid73037481',\n",
    "        'cardid69783235',\n",
    "        'cardid73144165',\n",
    "        'cardid33966233',\n",
    "        'cardid73046249',\n",
    "        'cardid69702399',\n",
    "        'cardid54078457',\n",
    "        'cardid71697753'\n",
    "    ]\n",
    "    \n",
    "    # Drop rows with matching IDs\n",
    "    df = df[~df['id'].isin(ids_to_remove)].reset_index(drop=True)\n",
    "    \n",
    "    #after observation \n",
    "    ids_to_update = ['cardid73059851', 'cardid72926775', 'cardid58806131']\n",
    "    \n",
    "    df.loc[df['id'].isin(ids_to_update), 'city'] = 'palghar'\n",
    "    df.loc[df['id'].isin(ids_to_update), 'location'] = 'palghar'\n",
    "    \n",
    "    #assign 'thane' to the city for all rows where location is 'ulhasnagar'\n",
    "    df.loc[df['location'] == 'ulhasnagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'agashi', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'bhabola', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'bolinj', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'diwanman', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'dongarpada road', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'evershine city', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'juchandra', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'morya nagar', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'oswal nagari', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'padmavati nagar bolinj', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'unique garden', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'rustomjee global city', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'wagholi', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'vinay nagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'yashwanth nagar', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'dongarpada', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'beverly park', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'padrikhan wadi', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'medetiya nagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'hatkesh udhog nagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'kashigaon', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'kashimira', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'sector 8 shanti nagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'shanti vihar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'chulne', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'mahajan wadi', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'sector 9 shanti nagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'chandan shanti', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'pleasant park', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'sector 3 shanti nagar', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'poonam sagar complex', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'stella', 'city'] = 'palghar'\n",
    "    df.loc[df['location'] == 'ramdev park', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'golden nest phase 1', 'city'] = 'thane'\n",
    "    df.loc[df['location'] == 'madhuban township', 'city'] = 'palghar'\n",
    "    \n",
    "    # Update city to 'thane' where address starts with 'mira' (case insensitive)\n",
    "    df.loc[df['address'].str.lower().str.startswith('mira', na=False), 'city'] = 'thane'\n",
    "    \n",
    "    #make thane in city for all this ids\n",
    "    ids_to_update = [\n",
    "        \"cardid72703033\",\n",
    "        \"cardid69846363\",\n",
    "        \"cardid73257889\",\n",
    "        \"cardid56191653\",\n",
    "        \"cardid72796607\",\n",
    "        \"cardid73026297\",\n",
    "        \"cardid72794677\",\n",
    "        \"cardid66964031\",\n",
    "        \"cardid58541153\",\n",
    "        \"cardid73076791\",\n",
    "        \"cardid72794677\",\n",
    "        \"cardid53323155\",\n",
    "        \"cardid69812109\",\n",
    "        \"cardid69665873\",\n",
    "        \"cardid70673145\",\n",
    "        \"cardid70120173\",\n",
    "        \"cardid60101171\",\n",
    "        \"cardid73012265\",\n",
    "        \"cardid73028981\",\n",
    "        \"cardid71481487\",\n",
    "        \"cardid67617413\",\n",
    "        \"cardid53977959\"\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    df.loc[df['id'].isin(ids_to_update), 'city'] = 'thane'\n",
    "    \n",
    "    #make palghar in city for all this ids\n",
    "    ids_to_update = [\n",
    "        \"cardid72923721\",\n",
    "        \"cardid61647785\",\n",
    "        \"cardid70476757\",\n",
    "        \"cardid72179863\",\n",
    "        \"cardid72846389\",\n",
    "        \"cardid73127129\",\n",
    "        \"cardid61883771\",\n",
    "        \"cardid72998493\",\n",
    "        \"cardid73114181\",\n",
    "        \"cardid71923233\",\n",
    "        \"cardid63887703\",\n",
    "        \"cardid72831163\"\n",
    "    ]\n",
    "    \n",
    "    df.loc[df['id'].isin(ids_to_update), 'city'] = 'palghar'\n",
    "    \n",
    "    #make navi mumbai in city for all this ids\n",
    "    ids_to_update = [\n",
    "        \"cardid62724753\"\n",
    "    ]\n",
    "    \n",
    "    df.loc[df['id'].isin(ids_to_update), 'city'] = 'navi mumbai'\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    # Create a mask for rows where 'lattitude' starts with 16, 12, or 9\n",
    "    mask = (\n",
    "        df['lattitude'].astype(str).str.startswith('16') |\n",
    "        df['lattitude'].astype(str).str.startswith('12') |\n",
    "        df['lattitude'].astype(str).str.startswith('9')\n",
    "    )\n",
    "    \n",
    "    # Replace only 'lattitude' and 'longitude' with NaN for those rows\n",
    "    df.loc[mask, ['lattitude', 'longitude']] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #drop columns\n",
    "    df.drop(['numberofrooms','bb_beds','leftbb_beds','bb_bed','leftbb_bed','multi_bed_filled','bb_baths','leftbb_baths','bb_bath','leftbb_bath','multi_bath_filled',\n",
    "             'bb_covered-parking','leftbb_covered-parking','many_car parking','leftmany_car parking','md_price breakup','property_loc','many_transaction type',\n",
    "             'leftmany_transaction type','many_type of ownership','leftmany_type of ownership','many_status', 'leftmany_status','many_lifts','md_lift','leftmany_lifts',\n",
    "             'many_lift','leftmany_lift','multi_lift_filled','aboutpjt_total floors','floor_work_1','many_floor','leftmany_floor','md_floors allowed for construction',\n",
    "             'construction_1','many_age of construction','leftmany_age of construction','bb_balcony', 'leftbb_balcony', 'bb_balconies','leftbb_balconies',\n",
    "             'leftmany_additional rooms', 'balcony1', 'many_additional rooms','extra_room', 'md_additional rooms','leftmany_facing','many_facing','ap_unit','ap_tower',\n",
    "             'ap_tower & unit','geo','potentialaction','md_overlooking','room_type','aboutpjt_project size','educational institute_1','educational institute_2',\n",
    "             'educational institute_3','educational institute_4','educational institute_5','transportation hub_1','transportation hub_2','transportation hub_3',\n",
    "             'transportation hub_4','transportation hub_5','shopping centre_1','shopping centre_2','shopping centre_3','shopping centre_4','shopping centre_5',\n",
    "             'commercial hub_1','commercial hub_2','commercial hub_3','commercial hub_4','commercial hub_5','hospital_1','hospital_2','hospital_3','hospital_4','hospital_5',\n",
    "             'tourist spot_1','tourist spot_2','tourist spot_3','tourist spot_4','education', 'transport', 'shopping_centre', 'commercial_hub', 'hospital', 'tourist',\n",
    "             'url','image','image_urls','name','wholeaddress','address','locality_rank', 'locality_url_rating'\n",
    "            ],axis=1,inplace=True)\n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "    return df\n",
    "\n",
    "def property_missingness_identification(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = data.copy()\n",
    "    #drop more than 70% missing value columns \n",
    "    cols_to_drop = ['tourist_mean_km', 'tourist_min_km', 'hospital_mean_km', 'hospital_min_km']\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "\n",
    "def perform_property_data_cleaning(data: pd.DataFrame, saved_data_path: Path) -> None:\n",
    "    cleaned_data = (\n",
    "        data\n",
    "        .pipe(basic_cleaning)\n",
    "        .pipe(property_missingness_identification)\n",
    "    )\n",
    "    cleaned_data.to_csv(saved_data_path, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_path = Path(__file__).parent.parent.parent\n",
    "    data_load_path = root_path / \"data\" / \"f_original magicbricks cleaned 12022 data.csv\"\n",
    "    cleaned_data_save_path = root_path / \"files_vscode\" / \"data\" / \"py_cleaned_data.csv\"\n",
    "\n",
    "    df = load_data(data_load_path)\n",
    "    perform_property_data_cleaning(df, cleaned_data_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d24ac10-9ae2-4548-b8e3-e183a9a4ba01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3a5a0-49cd-4e05-9b69-b59db7ec0679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671eeff-3d04-42df-a543-ed38f51a1211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe102c-8d52-455d-b5ad-2eaf01195d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9fc68a-8359-4d3d-b624-5d14d65df59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71573ece-1924-497b-8733-a3899e4ba3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
